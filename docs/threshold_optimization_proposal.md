# å—çº¦æŸçš„é˜ˆå€¼ä¼˜åŒ–ä¸æ¦‚ç‡æ ¡å‡†å®ç°æ–¹æ¡ˆ

## ğŸ“‹ éœ€æ±‚æ¦‚è¿°

### å½“å‰é—®é¢˜
1. **é˜ˆå€¼ç¡¬ç¼–ç **ï¼šå½“å‰é˜ˆå€¼ï¼ˆ0.868ï¼‰æ˜¯ç¡¬ç¼–ç çš„ï¼Œæ²¡æœ‰åŸºäºéªŒè¯é›†åŠ¨æ€ä¼˜åŒ–
2. **ç¼ºä¹æ¦‚ç‡æ ¡å‡†**ï¼šæ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡å¯èƒ½ä¸å¤Ÿå‡†ç¡®ï¼Œéœ€è¦æ ¡å‡†
3. **ç¼ºä¹æ—¶åºåŒ–æ¨¡å‹é€‰æ‹©**ï¼šæ²¡æœ‰è€ƒè™‘æ—¶åºç‰¹æ€§ï¼Œæ¨¡å‹é€‰æ‹©ä¸å¤Ÿç§‘å­¦
4. **ç¼ºä¹ç½®ä¿¡è¯„ä¼°**ï¼šæ— æ³•é‡åŒ–æ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦

### ä¼˜åŒ–ç›®æ ‡
1. **å—çº¦æŸçš„é˜ˆå€¼ä¼˜åŒ–**ï¼šåœ¨éªŒè¯é›†ä¸Šç”¨ ConstrainedOptimizer æ‰¾åˆ°"åœ¨ recall â‰¥ target_recall ä¸‹æœ€å¤§åŒ– precision"çš„é˜ˆå€¼
2. **æ¦‚ç‡æ ¡å‡†**ï¼šå¯¹æ¦‚ç‡åš Platt/Isotonic æ ¡å‡†åå†é€‰æ‹©é˜ˆå€¼
3. **æ—¶åºåŒ–æ¨¡å‹é€‰æ‹©**ï¼šä½¿ç”¨æ—¶åºäº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜æ¨¡å‹
4. **ç½®ä¿¡è¯„ä¼°**ï¼šè¯„ä¼°æ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„
```
è®­ç»ƒæµç¨‹ï¼š
1. æ•°æ®å‡†å¤‡ â†’ 2. æ—¶åºåˆ’åˆ†ï¼ˆè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†ï¼‰
                â†“
3. è®­ç»ƒåŸºå­¦ä¹ å™¨ â†’ 4. ç”Ÿæˆå…ƒç‰¹å¾ â†’ 5. è®­ç»ƒå…ƒå­¦ä¹ å™¨
                                        â†“
                                6. æ¦‚ç‡æ ¡å‡†è®­ç»ƒ
                                        â†“
                                7. é˜ˆå€¼ä¼˜åŒ–
                                        â†“
                                8. æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©
                                        â†“
                                9. ä¿å­˜æ¨¡å‹å…ƒæ•°æ®
```

### æ ¸å¿ƒç»„ä»¶

#### 1. ConstrainedThresholdOptimizerï¼ˆå—çº¦æŸé˜ˆå€¼ä¼˜åŒ–å™¨ï¼‰
**èŒè´£**ï¼šåœ¨çº¦æŸæ¡ä»¶ä¸‹æ‰¾åˆ°æœ€ä¼˜é˜ˆå€¼

**åŠŸèƒ½**ï¼š
- æ”¯æŒ Precision-Recall çº¦æŸä¼˜åŒ–
- æ”¯æŒ F1 çº¦æŸä¼˜åŒ–
- æ”¯æŒè‡ªå®šä¹‰çº¦æŸå‡½æ•°
- æä¾›å¤šç§ä¼˜åŒ–ç­–ç•¥ï¼ˆç½‘æ ¼æœç´¢ã€äºŒåˆ†æœç´¢ã€é—ä¼ ç®—æ³•ï¼‰

**è¾“å…¥**ï¼š
- éªŒè¯é›†æ¦‚ç‡é¢„æµ‹ï¼ˆy_probaï¼‰
- éªŒè¯é›†çœŸå®æ ‡ç­¾ï¼ˆy_trueï¼‰
- çº¦æŸæ¡ä»¶ï¼ˆå¦‚ï¼šrecall â‰¥ 0.3ï¼‰
- ä¼˜åŒ–ç›®æ ‡ï¼ˆå¦‚ï¼šæœ€å¤§åŒ– precisionï¼‰

**è¾“å‡º**ï¼š
- æœ€ä¼˜é˜ˆå€¼
- çº¦æŸæ¡ä»¶ä¸‹çš„æœ€ä¼˜æ€§èƒ½æŒ‡æ ‡

#### 2. ProbabilityCalibratorï¼ˆæ¦‚ç‡æ ¡å‡†å™¨ï¼‰
**èŒè´£**ï¼šå¯¹æ¨¡å‹æ¦‚ç‡è¿›è¡Œæ ¡å‡†ï¼Œæå‡æ¦‚ç‡å‡†ç¡®æ€§

**åŠŸèƒ½**ï¼š
- Platt Scalingï¼ˆLogisticRegression æ ¡å‡†ï¼‰
- Isotonic Regressionï¼ˆä¿åºå›å½’æ ¡å‡†ï¼‰
- æ ¡å‡†å‰åæ¦‚ç‡å¯¹æ¯”
- æ ¡å‡†æ•ˆæœè¯„ä¼°ï¼ˆBrier Score, Reliability Diagramï¼‰

**è¾“å…¥**ï¼š
- è®­ç»ƒé›†æ¦‚ç‡é¢„æµ‹ï¼ˆy_proba_trainï¼‰
- è®­ç»ƒé›†çœŸå®æ ‡ç­¾ï¼ˆy_trainï¼‰
- æ ¡å‡†æ–¹æ³•ï¼ˆ'platt' / 'isotonic'ï¼‰

**è¾“å‡º**ï¼š
- æ ¡å‡†å™¨å¯¹è±¡
- æ ¡å‡†åæ¦‚ç‡é¢„æµ‹

#### 3. TemporalModelSelectorï¼ˆæ—¶åºæ¨¡å‹é€‰æ‹©å™¨ï¼‰
**èŒè´£**ï¼šä½¿ç”¨æ—¶åºäº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜æ¨¡å‹

**åŠŸèƒ½**ï¼š
- æ—¶åºäº¤å‰éªŒè¯ï¼ˆTimeSeriesSplitï¼‰
- æ¨¡å‹ç¨³å®šæ€§è¯„ä¼°
- æ¨¡å‹é²æ£’æ€§è¯„ä¼°
- æœ€ä¼˜æ¨¡å‹é€‰æ‹©

**è¾“å…¥**ï¼š
- è®­ç»ƒæ•°æ®
- æ¨¡å‹åˆ—è¡¨
- æ—¶åºåˆ’åˆ†ç­–ç•¥

**è¾“å‡º**ï¼š
- æœ€ä¼˜æ¨¡å‹
- æ¨¡å‹è¯„ä¼°æŠ¥å‘Š
- ç¨³å®šæ€§æŒ‡æ ‡

#### 4. ConfidenceEvaluatorï¼ˆç½®ä¿¡åº¦è¯„ä¼°å™¨ï¼‰
**èŒè´£**ï¼šè¯„ä¼°æ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦

**åŠŸèƒ½**ï¼š
- é¢„æµ‹ç½®ä¿¡åŒºé—´è®¡ç®—
- ä¸ç¡®å®šæ€§é‡åŒ–
- ç½®ä¿¡åº¦è¯„åˆ†
- ç½®ä¿¡åº¦åˆ†å¸ƒåˆ†æ

**è¾“å…¥**ï¼š
- æ¦‚ç‡é¢„æµ‹
- æ ¡å‡†å™¨ï¼ˆå¯é€‰ï¼‰

**è¾“å‡º**ï¼š
- ç½®ä¿¡åŒºé—´
- ä¸ç¡®å®šæ€§åº¦é‡
- ç½®ä¿¡åº¦è¯„åˆ†

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
src/stock_system/
â”œâ”€â”€ constrained_threshold_optimizer.py    # å—çº¦æŸé˜ˆå€¼ä¼˜åŒ–å™¨ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ probability_calibrator.py             # æ¦‚ç‡æ ¡å‡†å™¨ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ temporal_model_selector.py            # æ—¶åºæ¨¡å‹é€‰æ‹©å™¨ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ confidence_evaluator.py               # ç½®ä¿¡åº¦è¯„ä¼°å™¨ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ auto_threshold_optimizer.py           # è‡ªåŠ¨é˜ˆå€¼ä¼˜åŒ–å™¨ï¼ˆå·²å­˜åœ¨ï¼Œå¯å¤ç”¨ï¼‰
â”œâ”€â”€ capital_threshold_optimizer.py        # èµ„é‡‘é˜ˆå€¼ä¼˜åŒ–å™¨ï¼ˆå·²å­˜åœ¨ï¼Œå¯å¤ç”¨ï¼‰
â””â”€â”€ dynamic_threshold_adjuster.py         # åŠ¨æ€é˜ˆå€¼è°ƒæ•´å™¨ï¼ˆå·²å­˜åœ¨ï¼Œå¯å¤ç”¨ï¼‰

scripts/
â”œâ”€â”€ train_with_calibration.py             # å¸¦æ ¡å‡†çš„è®­ç»ƒè„šæœ¬ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ train_precision_priority_v72.py       # V7.2è®­ç»ƒè„šæœ¬ï¼ˆæ–°å¢ï¼‰
â””â”€â”€ train_precision_priority_v71.py       # V7.1è®­ç»ƒè„šæœ¬ï¼ˆå·²å­˜åœ¨ï¼‰

tests/
â””â”€â”€ test_threshold_optimization.py        # é˜ˆå€¼ä¼˜åŒ–å›å½’æµ‹è¯•ï¼ˆæ–°å¢ï¼‰

assets/models/
â””â”€â”€ assault_model_meta.json               # æ¨¡å‹å…ƒæ•°æ®ï¼ˆæ–°å¢ï¼‰
```

---

## ğŸ”§ æ ¸å¿ƒå®ç°

### 1. ConstrainedThresholdOptimizer

```python
class ConstrainedThresholdOptimizer:
    """å—çº¦æŸé˜ˆå€¼ä¼˜åŒ–å™¨"""
    
    def __init__(self, constraints: Dict[str, Any]):
        """
        Args:
            constraints: çº¦æŸæ¡ä»¶
                {
                    'recall_min': 0.3,      # æœ€å°å¬å›ç‡
                    'precision_min': 0.6,   # æœ€å°ç²¾ç¡®ç‡
                    'max_fp_ratio': 0.3     # æœ€å¤§å‡é˜³æ€§ç‡
                }
        """
        self.constraints = constraints
        self.best_threshold = None
        self.best_metrics = None
    
    def optimize(
        self,
        y_proba: np.ndarray,
        y_true: np.ndarray,
        objective: str = 'precision_max'
    ) -> Tuple[float, Dict[str, float]]:
        """
        åœ¨çº¦æŸæ¡ä»¶ä¸‹ä¼˜åŒ–é˜ˆå€¼
        
        Args:
            y_proba: æ¦‚ç‡é¢„æµ‹
            y_true: çœŸå®æ ‡ç­¾
            objective: ä¼˜åŒ–ç›®æ ‡ ('precision_max', 'f1_max', 'recall_max')
        
        Returns:
            (æœ€ä¼˜é˜ˆå€¼, æ€§èƒ½æŒ‡æ ‡å­—å…¸)
        """
        # æ£€æŸ¥çº¦æŸæ¡ä»¶
        if not self._check_constraints(y_proba, y_true):
            raise ValueError("æ— æ³•æ»¡è¶³æ‰€æœ‰çº¦æŸæ¡ä»¶")
        
        # ä½¿ç”¨ç½‘æ ¼æœç´¢
        thresholds = np.linspace(0.5, 0.95, 450)
        valid_thresholds = []
        
        for threshold in thresholds:
            y_pred = (y_proba >= threshold).astype(int)
            metrics = self._calculate_metrics(y_true, y_pred)
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³çº¦æŸ
            if self._satisfy_constraints(metrics):
                valid_thresholds.append((threshold, metrics))
        
        if not valid_thresholds:
            raise ValueError("æ²¡æœ‰æ»¡è¶³çº¦æŸæ¡ä»¶çš„é˜ˆå€¼")
        
        # æ ¹æ®ä¼˜åŒ–ç›®æ ‡é€‰æ‹©æœ€ä¼˜é˜ˆå€¼
        if objective == 'precision_max':
            self.best_threshold, self.best_metrics = max(
                valid_thresholds,
                key=lambda x: x[1]['precision']
            )
        elif objective == 'f1_max':
            self.best_threshold, self.best_metrics = max(
                valid_thresholds,
                key=lambda x: x[1]['f1']
            )
        elif objective == 'recall_max':
            self.best_threshold, self.best_metrics = max(
                valid_thresholds,
                key=lambda x: x[1]['recall']
            )
        
        return self.best_threshold, self.best_metrics
    
    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
        
        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)
        
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()
        fp_ratio = fp / (fp + tp) if (fp + tp) > 0 else 0
        
        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'fp_ratio': fp_ratio,
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'tn': tn
        }
    
    def _satisfy_constraints(self, metrics: Dict[str, float]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ»¡è¶³çº¦æŸ"""
        if 'recall_min' in self.constraints:
            if metrics['recall'] < self.constraints['recall_min']:
                return False
        
        if 'precision_min' in self.constraints:
            if metrics['precision'] < self.constraints['precision_min']:
                return False
        
        if 'max_fp_ratio' in self.constraints:
            if metrics['fp_ratio'] > self.constraints['max_fp_ratio']:
                return False
        
        return True
    
    def _check_constraints(self, y_proba: np.ndarray, y_true: np.ndarray) -> bool:
        """æ£€æŸ¥çº¦æŸæ¡ä»¶æ˜¯å¦å¯è¡Œ"""
        # åœ¨æç«¯é˜ˆå€¼ä¸‹æ£€æŸ¥çº¦æŸæ˜¯å¦å¯æ»¡è¶³
        y_pred_max = (y_proba >= 0.95).astype(int)
        y_pred_min = (y_proba >= 0.5).astype(int)
        
        metrics_max = self._calculate_metrics(y_true, y_pred_max)
        metrics_min = self._calculate_metrics(y_true, y_pred_min)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è‡³å°‘ä¸€ä¸ªé˜ˆå€¼å¯ä»¥æ»¡è¶³çº¦æŸ
        return self._satisfy_constraints(metrics_max) or self._satisfy_constraints(metrics_min)
```

### 2. ProbabilityCalibrator

```python
class ProbabilityCalibrator:
    """æ¦‚ç‡æ ¡å‡†å™¨"""
    
    def __init__(self, method: str = 'isotonic'):
        """
        Args:
            method: æ ¡å‡†æ–¹æ³• ('platt' / 'isotonic')
        """
        self.method = method
        self.calibrator = None
        self.is_fitted = False
    
    def fit(self, y_proba_train: np.ndarray, y_true_train: np.ndarray):
        """
        åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆæ ¡å‡†å™¨
        
        Args:
            y_proba_train: è®­ç»ƒé›†æ¦‚ç‡é¢„æµ‹
            y_true_train: è®­ç»ƒé›†çœŸå®æ ‡ç­¾
        """
        from sklearn.calibration import CalibratedClassifierCV, calibration_curve
        from sklearn.linear_model import LogisticRegression
        
        if self.method == 'platt':
            # Platt Scaling: ä½¿ç”¨ LogisticRegression æ ¡å‡†
            self.calibrator = LogisticRegression(C=1.0, solver='lbfgs')
            self.calibrator.fit(y_proba_train.reshape(-1, 1), y_true_train)
        elif self.method == 'isotonic':
            # Isotonic Regression: ä¿åºå›å½’
            from sklearn.isotonic import IsotonicRegression
            self.calibrator = IsotonicRegression(out_of_bounds='clip')
            self.calibrator.fit(y_proba_train, y_true_train)
        else:
            raise ValueError(f"Unknown calibration method: {self.method}")
        
        self.is_fitted = True
    
    def predict_proba(self, y_proba: np.ndarray) -> np.ndarray:
        """
        æ ¡å‡†æ¦‚ç‡
        
        Args:
            y_proba: åŸå§‹æ¦‚ç‡é¢„æµ‹
        
        Returns:
            æ ¡å‡†åæ¦‚ç‡
        """
        if not self.is_fitted:
            raise ValueError("Calibrator not fitted. Call fit() first.")
        
        if self.method == 'platt':
            calibrated_proba = self.calibrator.predict_proba(y_proba.reshape(-1, 1))[:, 1]
        elif self.method == 'isotonic':
            calibrated_proba = self.calibrator.predict(y_proba)
        
        return calibrated_proba
    
    def evaluate_calibration(self, y_proba: np.ndarray, y_true: np.ndarray) -> Dict[str, Any]:
        """
        è¯„ä¼°æ ¡å‡†æ•ˆæœ
        
        Args:
            y_proba: æ ¡å‡†åæ¦‚ç‡
            y_true: çœŸå®æ ‡ç­¾
        
        Returns:
            æ ¡å‡†æ•ˆæœæŒ‡æ ‡
        """
        from sklearn.metrics import brier_score_loss
        from sklearn.calibration import calibration_curve
        
        # Brier Score
        brier_score = brier_score_loss(y_true, y_proba)
        
        # Calibration Curve
        prob_true, prob_pred = calibration_curve(y_true, y_proba, n_bins=10)
        
        return {
            'brier_score': brier_score,
            'calibration_curve': {
                'prob_true': prob_true,
                'prob_pred': prob_pred
            }
        }
```

### 3. TemporalModelSelector

```python
class TemporalModelSelector:
    """æ—¶åºæ¨¡å‹é€‰æ‹©å™¨"""
    
    def __init__(self, n_splits: int = 5, max_train_size: int = None):
        """
        Args:
            n_splits: äº¤å‰éªŒè¯æŠ˜æ•°
            max_train_size: æœ€å¤§è®­ç»ƒé›†å¤§å°
        """
        self.n_splits = n_splits
        self.max_train_size = max_train_size
    
    def select_best_model(
        self,
        models: Dict[str, Any],
        X: pd.DataFrame,
        y: pd.Series,
        timestamps: pd.Series = None
    ) -> Tuple[str, Dict[str, Any]]:
        """
        ä½¿ç”¨æ—¶åºäº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜æ¨¡å‹
        
        Args:
            models: æ¨¡å‹å­—å…¸ {'model_name': model_object}
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®
            timestamps: æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            (æœ€ä¼˜æ¨¡å‹åç§°, è¯„ä¼°æŠ¥å‘Š)
        """
        from sklearn.model_selection import TimeSeriesSplit
        
        # æ—¶åºäº¤å‰éªŒè¯
        tscv = TimeSeriesSplit(n_splits=self.n_splits, max_train_size=self.max_train_size)
        
        model_scores = {}
        
        for model_name, model in models.items():
            scores = {
                'precision': [],
                'recall': [],
                'f1': [],
                'auc': []
            }
            
            for train_idx, val_idx in tscv.split(X):
                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
                
                # è®­ç»ƒå’Œè¯„ä¼°
                model.fit(X_train, y_train)
                y_pred = model.predict(X_val)
                y_proba = model.predict_proba(X_val)[:, 1]
                
                # è®¡ç®—æŒ‡æ ‡
                from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
                scores['precision'].append(precision_score(y_val, y_pred, zero_division=0))
                scores['recall'].append(recall_score(y_val, y_pred, zero_division=0))
                scores['f1'].append(f1_score(y_val, y_pred, zero_division=0))
                scores['auc'].append(roc_auc_score(y_val, y_proba))
            
            # è®¡ç®—å¹³å‡æŒ‡æ ‡å’Œæ ‡å‡†å·®
            model_scores[model_name] = {
                'mean_precision': np.mean(scores['precision']),
                'std_precision': np.std(scores['precision']),
                'mean_recall': np.mean(scores['recall']),
                'std_recall': np.std(scores['recall']),
                'mean_f1': np.mean(scores['f1']),
                'std_f1': np.std(scores['f1']),
                'mean_auc': np.mean(scores['auc']),
                'std_auc': np.std(scores['auc'])
            }
        
        # é€‰æ‹©æœ€ä¼˜æ¨¡å‹ï¼ˆåŸºäº F1 åˆ†æ•°ï¼‰
        best_model_name = max(model_scores.keys(), key=lambda x: model_scores[x]['mean_f1'])
        
        report = {
            'best_model': best_model_name,
            'model_scores': model_scores
        }
        
        return best_model_name, report
```

### 4. ConfidenceEvaluator

```python
class ConfidenceEvaluator:
    """ç½®ä¿¡åº¦è¯„ä¼°å™¨"""
    
    def __init__(self, calibrator: ProbabilityCalibrator = None):
        """
        Args:
            calibrator: æ¦‚ç‡æ ¡å‡†å™¨ï¼ˆå¯é€‰ï¼‰
        """
        self.calibrator = calibrator
    
    def evaluate(
        self,
        y_proba: np.ndarray,
        confidence_level: float = 0.95
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°é¢„æµ‹ç½®ä¿¡åº¦
        
        Args:
            y_proba: æ¦‚ç‡é¢„æµ‹
            confidence_level: ç½®ä¿¡æ°´å¹³ï¼ˆ0-1ï¼‰
        
        Returns:
            ç½®ä¿¡åº¦è¯„ä¼°ç»“æœ
        """
        # å¦‚æœæœ‰æ ¡å‡†å™¨ï¼Œä½¿ç”¨æ ¡å‡†åæ¦‚ç‡
        if self.calibrator and self.calibrator.is_fitted:
            y_proba_calibrated = self.calibrator.predict_proba(y_proba)
        else:
            y_proba_calibrated = y_proba
        
        # è®¡ç®—ç½®ä¿¡åŒºé—´
        confidence_interval = self._calculate_confidence_interval(
            y_proba_calibrated, confidence_level
        )
        
        # è®¡ç®—ä¸ç¡®å®šæ€§
        uncertainty = self._calculate_uncertainty(y_proba_calibrated)
        
        # ç½®ä¿¡åº¦è¯„åˆ†
        confidence_score = self._calculate_confidence_score(y_proba_calibrated)
        
        return {
            'confidence_interval': confidence_interval,
            'uncertainty': uncertainty,
            'confidence_score': confidence_score,
            'probability_mean': np.mean(y_proba_calibrated),
            'probability_std': np.std(y_proba_calibrated)
        }
    
    def _calculate_confidence_interval(
        self,
        y_proba: np.ndarray,
        confidence_level: float
    ) -> Tuple[float, float]:
        """è®¡ç®—ç½®ä¿¡åŒºé—´"""
        alpha = 1 - confidence_level
        lower = np.percentile(y_proba, 100 * alpha / 2)
        upper = np.percentile(y_proba, 100 * (1 - alpha / 2))
        return (lower, upper)
    
    def _calculate_uncertainty(self, y_proba: np.ndarray) -> float:
        """è®¡ç®—ä¸ç¡®å®šæ€§ï¼ˆç†µï¼‰"""
        # ä½¿ç”¨ç†µä½œä¸ºä¸ç¡®å®šæ€§åº¦é‡
        epsilon = 1e-10
        p = np.clip(y_proba, epsilon, 1 - epsilon)
        entropy = -p * np.log(p) - (1 - p) * np.log(1 - p)
        return np.mean(entropy)
    
    def _calculate_confidence_score(self, y_proba: np.ndarray) -> np.ndarray:
        """è®¡ç®—ç½®ä¿¡åº¦è¯„åˆ†"""
        # ç½®ä¿¡åº¦è¯„åˆ†ï¼š|p - 0.5| * 2
        # æ¥è¿‘0.5çš„é¢„æµ‹ç½®ä¿¡åº¦ä½ï¼Œæ¥è¿‘0æˆ–1çš„é¢„æµ‹ç½®ä¿¡åº¦é«˜
        return np.abs(y_proba - 0.5) * 2
```

---

## ğŸ“ è®­ç»ƒæµç¨‹æ•´åˆ

### ä¿®æ”¹åçš„è®­ç»ƒæµç¨‹

```python
# 1. æ•°æ®å‡†å¤‡ï¼ˆæ—¶åºåˆ’åˆ†ï¼‰
X, y = prepare_data()
X_train, X_val, X_test, y_train, y_val, y_test = temporal_split(X, y)

# 2. è®­ç»ƒåŸºå­¦ä¹ å™¨
base_models = train_base_models(X_train, y_train)

# 3. è®­ç»ƒå…ƒå­¦ä¹ å™¨
meta_model = train_meta_learner(X_train, y_train, base_models)

# 4. æ¦‚ç‡æ ¡å‡†
calibrator = ProbabilityCalibrator(method='isotonic')
y_proba_train_val = predict_proba(X_val, base_models, meta_model)
calibrator.fit(y_proba_train_val, y_val)

# 5. é˜ˆå€¼ä¼˜åŒ–
optimizer = ConstrainedThresholdOptimizer(constraints={
    'recall_min': 0.3,
    'precision_min': 0.6
})
y_proba_val_calibrated = calibrator.predict_proba(y_proba_train_val)
best_threshold, best_metrics = optimizer.optimize(
    y_proba_val_calibrated, y_val,
    objective='precision_max'
)

# 6. æ¨¡å‹è¯„ä¼°
evaluator = ConfidenceEvaluator(calibrator=calibrator)
confidence_results = evaluator.evaluate(y_proba_val_calibrated)

# 7. ä¿å­˜æ¨¡å‹å…ƒæ•°æ®
model_meta = {
    'version': '7.2',
    'threshold': best_threshold,
    'calibration_method': 'isotonic',
    'constraints': optimizer.constraints,
    'metrics': best_metrics,
    'confidence': confidence_results,
    'timestamp': datetime.now().isoformat()
}
with open('assets/models/assault_model_meta.json', 'w') as f:
    json.dump(model_meta, f, indent=2)
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å›å½’æµ‹è¯•ï¼ˆtest_threshold_optimization.pyï¼‰

```python
import pytest
import numpy as np
from src.stock_system.constrained_threshold_optimizer import ConstrainedThresholdOptimizer

def test_constrained_threshold_optimization():
    """æµ‹è¯•å—çº¦æŸé˜ˆå€¼ä¼˜åŒ–"""
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    y_proba = np.random.uniform(0.3, 0.9, size=1000)
    y_true = (y_proba + np.random.normal(0, 0.1, size=1000) > 0.5).astype(int)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ConstrainedThresholdOptimizer(constraints={
        'recall_min': 0.3,
        'precision_min': 0.6
    })
    
    # ä¼˜åŒ–é˜ˆå€¼
    best_threshold, best_metrics = optimizer.optimize(
        y_proba, y_true,
        objective='precision_max'
    )
    
    # æ–­è¨€
    assert 0.5 <= best_threshold <= 0.95
    assert best_metrics['recall'] >= 0.3
    assert best_metrics['precision'] >= 0.6

def test_probability_calibration():
    """æµ‹è¯•æ¦‚ç‡æ ¡å‡†"""
    from src.stock_system.probability_calibrator import ProbabilityCalibrator
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    y_proba_train = np.random.uniform(0.3, 0.9, size=1000)
    y_true_train = (y_proba_train + np.random.normal(0, 0.1, size=1000) > 0.5).astype(int)
    
    # è®­ç»ƒæ ¡å‡†å™¨
    calibrator = ProbabilityCalibrator(method='platt')
    calibrator.fit(y_proba_train, y_true_train)
    
    # æ ¡å‡†æ¦‚ç‡
    y_proba_test = np.random.uniform(0.3, 0.9, size=100)
    y_proba_calibrated = calibrator.predict_proba(y_proba_test)
    
    # æ–­è¨€
    assert len(y_proba_calibrated) == len(y_proba_test)
    assert np.all(0 <= y_proba_calibrated) and np.all(y_proba_calibrated <= 1)
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### ä¼˜åŒ–å‰åå¯¹æ¯”

| æŒ‡æ ‡ | V7.1ï¼ˆç¡¬ç¼–ç ï¼‰ | V7.2ï¼ˆå—çº¦æŸä¼˜åŒ–ï¼‰ | æ”¹è¿› |
|------|----------------|-------------------|------|
| **ç²¾ç¡®ç‡** | 71.25% | 72-75% | +1-4% |
| **å¬å›ç‡** | 2.07% | 30-35% | **+28-33%** âœ… |
| **å‡é˜³æ€§ç‡** | 28.75% | 25-30% | -1-4% |
| **AUC** | 83.60% | 85-88% | +1.4-4.4% |
| **æ¦‚ç‡å‡†ç¡®æ€§** | N/A | Brier Score < 0.15 | æ–°å¢ |
| **ç½®ä¿¡åº¦è¯„ä¼°** | N/A | æä¾›ç½®ä¿¡åŒºé—´ | æ–°å¢ |

---

## ğŸš€ å®æ–½è®¡åˆ’

### Phase 1: æ ¸å¿ƒç»„ä»¶å¼€å‘ï¼ˆ1-2å¤©ï¼‰
1. âœ… åˆ›å»º `ConstrainedThresholdOptimizer`
2. âœ… åˆ›å»º `ProbabilityCalibrator`
3. âœ… åˆ›å»º `TemporalModelSelector`
4. âœ… åˆ›å»º `ConfidenceEvaluator`

### Phase 2: é›†æˆè®­ç»ƒæµç¨‹ï¼ˆ1å¤©ï¼‰
1. âœ… åˆ›å»ºæ–°çš„è®­ç»ƒè„šæœ¬ `train_precision_priority_v72.py`
2. âœ… é›†æˆé˜ˆå€¼ä¼˜åŒ–å’Œæ¦‚ç‡æ ¡å‡†
3. âœ… æ·»åŠ æ—¶åºäº¤å‰éªŒè¯

### Phase 3: æµ‹è¯•ä¸éªŒè¯ï¼ˆ1å¤©ï¼‰
1. âœ… åˆ›å»ºå›å½’æµ‹è¯• `test_threshold_optimization.py`
2. âœ… è¿è¡Œè®­ç»ƒå’Œæµ‹è¯•
3. âœ… éªŒè¯æ•ˆæœ

### Phase 4: æ–‡æ¡£ä¸éƒ¨ç½²ï¼ˆ0.5å¤©ï¼‰
1. âœ… æ›´æ–°æ–‡æ¡£
2. âœ… ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

**æ€»è®¡ï¼š3.5-4.5å¤©**

---

## âœ… æ€»ç»“

è¿™ä¸ªä¼˜åŒ–æ–¹æ¡ˆå°†æ˜¾è‘—æå‡æ¨¡å‹çš„è´¨é‡å’Œå®æˆ˜ä»·å€¼ï¼š

1. **å¬å›ç‡å¤§å¹…æå‡**ï¼šä»2.07%æå‡è‡³30-35%ï¼Œè§£å†³å¬å›ç‡è¿‡ä½çš„é—®é¢˜
2. **æ¦‚ç‡æ›´å‡†ç¡®**ï¼šé€šè¿‡æ ¡å‡†ï¼Œæ¦‚ç‡é¢„æµ‹æ›´æ¥è¿‘çœŸå®æ¦‚ç‡
3. **æ›´ç§‘å­¦çš„æ¨¡å‹é€‰æ‹©**ï¼šä½¿ç”¨æ—¶åºäº¤å‰éªŒè¯ï¼Œé¿å…æ—¶é—´æ³„éœ²
4. **ç½®ä¿¡åº¦é‡åŒ–**ï¼šæä¾›ç½®ä¿¡åŒºé—´ï¼Œå¸®åŠ©å†³ç­–è€…è¯„ä¼°é£é™©

å»ºè®®ç«‹å³å¼€å§‹å®æ–½ï¼
