# DeepQuant å¿«é€Ÿå‚è€ƒå¡

> **é¢å‘ç¨‹åºå‘˜çš„å¿«é€Ÿå‚è€ƒ**ï¼šæ ¸å¿ƒå‚æ•°ã€å¸¸ç”¨å‘½ä»¤ã€ä»£ç ç‰‡æ®µ

---

## ðŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### é…ç½®Token
```bash
# æ–¹å¼1: ç¼–è¾‘é…ç½®æ–‡ä»¶
vim config/.env
# æ·»åŠ : TUSHARE_TOKEN=your_token_here

# æ–¹å¼2: å‘½ä»¤è¡Œ
echo "TUSHARE_TOKEN=your_token_here" > config/.env
```

### è¿è¡Œè®­ç»ƒ
```bash
# é»˜è®¤å‚æ•°
python scripts/run_real_data_assault.py

# è‡ªå®šä¹‰å‚æ•°
python scripts/run_real_data_assault.py \
    --start-date 2022-01-01 \
    --end-date 2024-12-31 \
    --limit 500
```

---

## ðŸ“Š æ ¸å¿ƒå‚æ•°é€ŸæŸ¥

### æ•°æ®å‚æ•°
```python
# æ•°æ®èŒƒå›´
start_date: str = '2023-01-01'  # å¼€å§‹æ—¥æœŸ
end_date: str = '2025-12-30'    # ç»“æŸæ—¥æœŸ

# è‚¡ç¥¨ç­›é€‰
limit_stocks: int = 300         # è‚¡ç¥¨æ•°é‡
train_ratio: float = 0.8        # è®­ç»ƒé›†æ¯”ä¾‹

# è¿‡æ»¤è§„åˆ™ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰
exclude_kcb: bool = True        # æŽ’é™¤ç§‘åˆ›æ¿(688)
exclude_gem: bool = True        # æŽ’é™¤åˆ›ä¸šæ¿(300/301)
exclude_st: bool = True         # æŽ’é™¤STè‚¡
exclude_bj: bool = True         # æŽ’é™¤åŒ—äº¤æ‰€(BJ)
```

### æ ‡ç­¾å‚æ•°
```python
# æ ‡ç­¾å®šä¹‰
future_window: int = 10         # æœªæ¥çª—å£(å¤©)
positive_threshold: float = 0.05  # æ­£æ ·æœ¬é˜ˆå€¼(+5%)
negative_threshold: float = -0.03 # è´Ÿæ ·æœ¬é˜ˆå€¼(-3%)

# æ ·æœ¬åˆ’åˆ†
lookback_window: int = 20       # ç‰¹å¾è®¡ç®—çª—å£
min_samples: int = 100          # æœ€å°æ ·æœ¬æ•°
```

### æ¨¡åž‹å‚æ•°
```python
# RandomForest (å½“å‰ä½¿ç”¨)
model = RandomForestClassifier(
    n_estimators=100,           # æ ‘çš„æ•°é‡: 50-500
    max_depth=10,               # æœ€å¤§æ·±åº¦: 5-15
    min_samples_split=2,        # æœ€å°åˆ†è£‚æ ·æœ¬: 2-10
    min_samples_leaf=1,         # å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬: 1-5
    max_features='sqrt',        # æœ€å¤§ç‰¹å¾æ•°: sqrt/log2
    class_weight='balanced',    # ç±»åˆ«æƒé‡
    random_state=42             # éšæœºç§å­
)

# XGBoost (å¯é€‰)
model = xgb.XGBClassifier(
    max_depth=6,                # æœ€å¤§æ·±åº¦: 3-10
    learning_rate=0.1,          # å­¦ä¹ çŽ‡: 0.01-0.3
    n_estimators=100,           # è¿­ä»£æ¬¡æ•°: 50-300
    subsample=0.8,              # æ ·æœ¬é‡‡æ ·: 0.6-1.0
    colsample_bytree=0.8,       # ç‰¹å¾é‡‡æ ·: 0.6-1.0
    objective='binary:logistic',
    eval_metric='auc',
    random_state=42
)
```

### é€‰è‚¡å‚æ•°
```python
# é˜ˆå€¼è®¾ç½®
confidence_threshold: float = 0.6  # é¢„æµ‹æ¦‚çŽ‡é˜ˆå€¼: 0.6-0.8
min_probability: float = 0.5       # æœ€å°æ¦‚çŽ‡

# ä»“ä½ç®¡ç†
max_positions: int = 20            # æœ€å¤§æŒä»“æ•°: 10-30
position_size: float = 0.05        # å•è‚¡ä»“ä½: 0.02-0.1

# é£ŽæŽ§å‚æ•°
stop_loss: float = 0.08            # æ­¢æŸæ¯”ä¾‹: 0.05-0.15
take_profit: float = 0.15          # æ­¢ç›ˆæ¯”ä¾‹: 0.10-0.20
```

---

## ðŸ”§ å¸¸ç”¨ä»£ç ç‰‡æ®µ

### æ•°æ®åŠ è½½
```python
from stock_system.data_collector import MarketDataCollector

collector = MarketDataCollector()

# èŽ·å–è‚¡ç¥¨åˆ—è¡¨
stock_list = collector.get_stock_list()

# èŽ·å–å•åªè‚¡ç¥¨æ•°æ®
daily_data = collector.get_daily_data(
    ts_code='000001.SZ',
    start_date='2023-01-01',
    end_date='2023-12-31'
)

# æ‰¹é‡èŽ·å–
all_data = []
for _, stock in stock_list.head(100).iterrows():
    data = collector.get_daily_data(stock['ts_code'], start_date, end_date)
    data['ts_code'] = stock['ts_code']
    all_data.append(data)
```

### ç‰¹å¾å·¥ç¨‹
```python
from stock_system.assault_features import AssaultFeatureEngineer

engineer = AssaultFeatureEngineer()

# åˆ›å»ºæ‰€æœ‰ç‰¹å¾
df = engineer.create_all_features(df)

# å•ç‹¬åˆ›å»ºç‰¹å¾
df = engineer.create_capital_strength_features(df)
df = engineer.create_market_sentiment_features(df)
df = engineer.create_technical_momentum_features(df)
```

### æ¨¡åž‹è®­ç»ƒ
```python
from sklearn.ensemble import RandomForestClassifier

# æå–ç‰¹å¾å’Œæ ‡ç­¾
exclude_cols = ['ts_code', 'name', 'trade_date', 'target', 
                'future_return_5d', 'future_return_10d', 'future_return_20d']
feature_cols = [col for col in df.columns if col not in exclude_cols]

X = df[feature_cols].fillna(0)
y = df['target'].values

# è®­ç»ƒæ¨¡åž‹
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    class_weight='balanced'
)
model.fit(X, y)
```

### æ¨¡åž‹é¢„æµ‹
```python
from stock_system.predictor import StockPredictor

predictor = StockPredictor()

# é¢„æµ‹
result = predictor.predict(test_data)

# æŸ¥çœ‹ç»“æžœ
print(result[['ts_code', 'trade_date', 'predicted_label', 'predicted_prob']].head())

# é«˜ç½®ä¿¡åº¦é€‰è‚¡
high_conf = result[result['predicted_prob'] > 0.7]
print(f"é«˜ç½®ä¿¡åº¦è‚¡ç¥¨: {len(high_conf)} åª")
```

### æ¨¡åž‹è¯„ä¼°
```python
from sklearn.metrics import classification_report, roc_auc_score

# åˆ†ç±»æŠ¥å‘Š
print(classification_report(y_test, y_pred))

# AUC
auc = roc_auc_score(y_test, y_pred_proba)
print(f"AUC: {auc:.4f}")

# ç½®ä¿¡åº¦åˆ†æ¡¶
for threshold in [0.5, 0.6, 0.7, 0.8, 0.9]:
    mask = y_pred_proba > threshold
    if mask.sum() > 0:
        precision = (y_test[mask] == 1).sum() / mask.sum()
        avg_return = test_data[mask]['future_return_10d'].mean()
        print(f"é˜ˆå€¼>{threshold}: {mask.sum()}åª | ç²¾ç¡®çŽ‡:{precision:.2%} | æ”¶ç›Š:{avg_return:.2%}")
```

### ç‰¹å¾é‡è¦æ€§åˆ†æž
```python
import pandas as pd

# ç‰¹å¾é‡è¦æ€§
importances = model.feature_importances_
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': importances
}).sort_values('importance', ascending=False)

# æ‰“å°Top 20
print(feature_importance.head(20))

# å¯è§†åŒ–
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
plt.barh(feature_importance['feature'][:20], feature_importance['importance'][:20])
plt.title('Top 20 ç‰¹å¾é‡è¦æ€§')
plt.xlabel('é‡è¦æ€§')
plt.ylabel('ç‰¹å¾')
plt.tight_layout()
plt.show()
```

---

## ðŸ“ æ ¸å¿ƒæ–‡ä»¶é€ŸæŸ¥

### ä¸»ç¨‹åº
```
scripts/run_real_data_assault.py    # ä¸»è®­ç»ƒè„šæœ¬
src/main.py                         # ä¸»å…¥å£
```

### æ ¸å¿ƒæ¨¡å—
```
src/stock_system/
â”œâ”€â”€ data_collector.py               # æ•°æ®é‡‡é›†å™¨
â”œâ”€â”€ assault_features.py             # ç‰¹å¾å·¥ç¨‹
â”œâ”€â”€ predictor.py                    # é¢„æµ‹å™¨
â”œâ”€â”€ confidence_bucket.py            # ç½®ä¿¡åº¦åˆ†æž
â””â”€â”€ assault_decision_brain.py       # å†³ç­–å¤§è„‘
```

### é…ç½®æ–‡ä»¶
```
config/
â”œâ”€â”€ .env                            # çŽ¯å¢ƒå˜é‡
â”œâ”€â”€ tushare_config.json             # Tushareé…ç½®
â”œâ”€â”€ model_config.json               # æ¨¡åž‹é…ç½®
â””â”€â”€ short_term_assault_config.json  # ç­–ç•¥é…ç½®
```

---

## ðŸŽ¯ ç‰¹å¾å·¥ç¨‹è¯¦è§£

### èµ„é‡‘å¼ºåº¦ç‰¹å¾ (40%æƒé‡)

| ç‰¹å¾ | ä»£ç  | é˜ˆå€¼ |
|------|------|------|
| ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å æ¯” | `main_capital_inflow_ratio` | >5% |
| å¤§å•å‡€ä¹°å…¥çŽ‡ | `large_order_buy_rate` | >30% |
| èµ„é‡‘æµå…¥æŒç»­æ€§ | `capital_inflow_persistence` | â‰¥0.66 |
| åŒ—å‘èµ„é‡‘æµå…¥ | `northbound_capital_flow` | æ¿å—å‰20% |

### å¸‚åœºæƒ…ç»ªç‰¹å¾ (35%æƒé‡)

| ç‰¹å¾ | ä»£ç  | é˜ˆå€¼ |
|------|------|------|
| æ¿å—çƒ­åº¦æŒ‡æ•° | `sector_heat_index` | >0.1 |
| ä¸ªè‚¡æƒ…ç»ªå¾—åˆ† | `stock_sentiment_score` | >0.7 |
| ä¸Šæ¶¨å¤©æ•°å æ¯” | `up_days_ratio` | >0.6 |
| æƒ…ç»ªå‘¨æœŸä½ç½® | `sentiment_cycle_position` | ä¸Šå‡åˆæœŸ |

### æŠ€æœ¯åŠ¨é‡ç‰¹å¾ (25%æƒé‡)

| ç‰¹å¾ | ä»£ç  | é˜ˆå€¼ |
|------|------|------|
| å¢žå¼ºRSI | `enhanced_rsi` | >60 |
| é‡ä»·çªç ´å¼ºåº¦ | `volume_price_breakout_strength` | >2 |
| ç›˜ä¸­æ”»å‡»å½¢æ€ | `intraday_attack_pattern` | å­˜åœ¨æ˜Žæ˜¾æ”»å‡»æ³¢ |

---

## ðŸ› å¸¸è§é—®é¢˜æŽ’æŸ¥

### é—®é¢˜1: Tokenæœªé…ç½®
```
é”™è¯¯: ValueError('TUSHARE_TOKEN is not set in environment variables')

è§£å†³:
1. æ£€æŸ¥ config/.env æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. æ£€æŸ¥æ–‡ä»¶ä¸­æ˜¯å¦åŒ…å« TUSHARE_TOKEN
3. è¿è¡Œæ£€æŸ¥è„šæœ¬: python scripts/check_config.py
```

### é—®é¢˜2: ç‰¹å¾æ•°é‡ä¸º0
```
é”™è¯¯: ValueError('No features found')

è§£å†³:
1. æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«ä»·æ ¼å’Œæˆäº¤é‡å­—æ®µ
2. æ£€æŸ¥ç‰¹å¾å·¥ç¨‹ä»£ç æ˜¯å¦æ­£ç¡®æ‰§è¡Œ
3. æ‰“å°åˆ—å: print(df.columns.tolist())
```

### é—®é¢˜3: æµ‹è¯•é›†ä¸ºç©º
```
é”™è¯¯: ValueError('Test set is empty')

è§£å†³:
1. æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´æ˜¯å¦è¶³å¤Ÿ
2. æ£€æŸ¥ train_ratio å‚æ•°
3. ä½¿ç”¨80%/20%çš„æ—¶é—´åºåˆ—åˆ’åˆ†
```

### é—®é¢˜4: æ¨¡åž‹è®­ç»ƒå¤±è´¥
```
é”™è¯¯: RuntimeError('Model training failed')

è§£å†³:
1. æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰ç¼ºå¤±å€¼: df.isnull().sum()
2. æ£€æŸ¥ç‰¹å¾æ˜¯å¦ä¸ºæ•°å€¼ç±»åž‹: df.dtypes
3. æ£€æŸ¥æ ‡ç­¾æ˜¯å¦å¹³è¡¡: y.value_counts()
```

---

## ðŸ“ˆ æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. æ•°æ®åŠ è½½ä¼˜åŒ–
```python
# å¤šçº¿ç¨‹åŠ è½½
from concurrent.futures import ThreadPoolExecutor

def fetch_stock(stock_info):
    collector = MarketDataCollector()
    return collector.get_daily_data(stock_info['ts_code'], start_date, end_date)

with ThreadPoolExecutor(max_workers=10) as executor:
    futures = [executor.submit(fetch_stock, stock) for stock in stock_list]
    all_data = [f.result() for f in futures]
```

### 2. ç‰¹å¾é€‰æ‹©
```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(f_classif, k=30)
X_selected = selector.fit_transform(X_train, y_train)
```

### 3. è¶…å‚æ•°è°ƒä¼˜
```python
import optuna

def objective(trial):
    params = {
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'n_estimators': trial.suggest_int('n_estimators', 50, 300)
    }
    model = xgb.XGBClassifier(**params)
    score = cross_val_score(model, X_train, y_train, cv=5).mean()
    return score

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)
```

---

## ðŸŽ¨ è‡ªå®šä¹‰æ‰©å±•

### æ·»åŠ æ–°ç‰¹å¾
```python
def create_custom_feature(df):
    df = df.copy()
    
    # ä¾‹å¦‚ï¼šå¸ƒæž—å¸¦
    df['bb_upper'] = df['close'].rolling(20).mean() + 2*df['close'].rolling(20).std()
    df['bb_lower'] = df['close'].rolling(20).mean() - 2*df['close'].rolling(20).std()
    
    return df
```

### æ·»åŠ æ–°æ¨¡åž‹
```python
import lightgbm as lgb

model = lgb.LGBMClassifier(
    num_leaves=31,
    learning_rate=0.1,
    n_estimators=100
)
model.fit(X_train, y_train)
```

### æ·»åŠ æ–°ç­–ç•¥
```python
class CustomStrategy:
    def generate_signals(self, df):
        df['signal'] = 0
        df.loc[df['close'] > df['ma20'], 'signal'] = 1
        df.loc[df['close'] < df['ma20'], 'signal'] = -1
        return df
```

---

## ðŸ“ž èŽ·å–å¸®åŠ©

- å®Œæ•´æ–‡æ¡£: `docs/technical_documentation.md`
- å¿«é€Ÿå¼€å§‹: `docs/REAL_DATA_QUICKSTART.md`
- ä½¿ç”¨æŒ‡å—: `docs/real_data_usage_guide.md`
- ç¤ºä¾‹ä»£ç : `assets/reports/`

---

**ç‰ˆæœ¬**: v1.0  
**æ›´æ–°**: 2026-02-04
