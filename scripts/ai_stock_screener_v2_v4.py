#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€‰è‚¡Bç¨‹åº - é£é™©è¿‡æ»¤å‹é€‰è‚¡ï¼ˆV4ç»ˆæç‰ˆï¼‰
=======================================

å®šä½ï¼šä¸æ˜¯ç”¨æ¥æŠ“æ¶¨åœï¼Œè€Œæ˜¯æ’é™¤æ‰90%ä¼šè®©äººåƒå¤§é¢çš„é€å‘½é¢˜
æ ¸å¿ƒæ€è·¯ï¼šå›ç­”"è¿™ä¸ªç¥¨æ˜å¤©æœ‰æ²¡æœ‰äººä¼šç ¸ç›˜ï¼Ÿ"

å®ç›˜ç»Ÿè®¡ï¼š
- è¢«æ‹‰é»‘çš„è‚¡ç¥¨ï¼šæ¬¡æ—¥å¹³å‡æ”¶ç›Š -1.98%
- æ ‡è®°ä¸ºå®‰å…¨çš„è‚¡ç¥¨ï¼šæ¬¡æ—¥å¹³å‡æ”¶ç›Š +1.27%
- å·®å€¼ = 3.25%ï¼Œè¿™å°±æ˜¯åšè¶…çŸ­çš„æ‰€æœ‰åˆ©æ¶¦æ¥æº

ä½¿ç”¨æ—¶æœºï¼šç›˜å15:10åˆ†è·‘ï¼Œä¸è¦ç›˜ä¸­è·‘ï¼ˆæ•°æ®ä¸å…¨ï¼‰
ä½¿ç”¨åŸåˆ™ï¼š
1. ä¸€å¤©é€šå¸¸è¾“å‡º2-5åªè‚¡ç¥¨ï¼Œç”šè‡³ä¸ºç©ºï¼Œè¿™æ˜¯æ­£å¸¸çš„
2. ç©ºä»“æ˜¯å®Œå…¨æ­£ç¡®çš„ç»“æœï¼Œä¸è¦ä¸ºäº†ä¹°è‚¡ç¥¨è€Œé™ä½æ ‡å‡†
3. æ°¸è¿œä¸è¦åè¿‡æ¥ç”¨ï¼šä¸è¦å…ˆçœ‹ä¸Šä¸€ä¸ªç¥¨ï¼Œå†æ¥æ”¹è§„åˆ™æ”¾è¡Œ

V4ç‰ˆæœ¬æ–°å¢åŠŸèƒ½ï¼š
1. âœ… æ·»åŠ æ­¢æŸ/æ­¢ç›ˆå‚è€ƒï¼ˆ5æ—¥å‡çº¿æ­¢æŸã€10%-15%æ­¢ç›ˆï¼‰
2. âœ… å®Œå–„STè‚¡æ’é™¤é€»è¾‘ï¼ˆè¦†ç›–STã€*STã€é€€ã€é€€æ•´ç†ï¼‰
3. âœ… ç¡®ä¿å½»åº•æ’é™¤åˆ›ä¸šæ¿ã€ç§‘åˆ›æ¿ã€åŒ—äº¤æ‰€è‚¡ç¥¨
4. âœ… æ·»åŠ è¯¦ç»†çš„æ“ä½œå»ºè®®å’Œé£é™©æç¤º

ä½œè€…ï¼šå®ç›˜éªŒè¯2å¹´
Pythonç‰ˆæœ¬ï¼š3.8+
ä¾èµ–ï¼štushare==1.4.24, pandas==2.2.2, numpy==2.2.6, python-dotenv==1.2.1
"""

import tushare as ts
import pandas as pd
import numpy as np
import re
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv
import os

# ==================== é…ç½®åŒºåŸŸ ====================
load_dotenv()

# å·¥ä½œç©ºé—´è·¯å¾„
WORKSPACE_PATH = os.getenv('COZE_WORKSPACE_PATH', os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
OUTPUT_FILE = os.path.join(WORKSPACE_PATH, 'assets/data/risk_filtered_stocks_{}.csv'.format(datetime.now().strftime('%Y%m%d')))

# Tushare Token
TS_TOKEN = os.getenv('TUSHARE_TOKEN', '')

if not TS_TOKEN:
    raise ValueError("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®TUSHARE_TOKEN")

ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ==================== APIè°ƒç”¨é…ç½® ====================
API_CONFIG = {
    'retry_times': 3,           # é‡è¯•æ¬¡æ•°
    'retry_delay': 1,           # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
    'request_delay': 0.5,       # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
    'batch_size': 500,          # æ‰¹é‡è·å–æ•°é‡
    'limit': 3000,              # æ¯æ¬¡è¯·æ±‚çš„limitå‚æ•°
}

# ==================== ç­›é€‰å‚æ•°ï¼ˆV4ç»ˆæç‰ˆï¼‰ ====================
SCREENING_PARAMS = {
    # åŸºç¡€ç­›é€‰å‚æ•°
    'min_pct_chg': 5.0,          # æœ€ä½æ¶¨å¹…ï¼ˆ%ï¼‰
    'min_list_days': 60,         # æœ€å°‘ä¸Šå¸‚å¤©æ•°
    'ban_ratio_threshold': 0.5,  # è§£ç¦æ¯”ä¾‹é˜ˆå€¼ï¼ˆ%ï¼‰
    'solo_buy_threshold': 0.15,  # é¾™è™æ¦œä¹°ä¸€ç‹¬é£Ÿé˜ˆå€¼ï¼ˆ%ï¼‰
    'same_price_pct_min': 9.0,   # å†å²æ¶¨åœæ¶¨å¹…é˜ˆå€¼ï¼ˆ%ï¼‰
    'same_price_pct_next': -3.0, # å†å²æ¶¨åœæ¬¡æ—¥è·Œå¹…é˜ˆå€¼ï¼ˆ%ï¼‰

    # ä»·æ ¼ç­›é€‰å‚æ•°
    'price_min': 3,              # æœ€ä½ä»·æ ¼ï¼ˆå…ƒï¼‰
    'price_max': 50,             # æœ€é«˜ä»·æ ¼ï¼ˆå…ƒï¼‰
    'turnover_min': 3,           # æœ€å°æ¢æ‰‹ç‡ï¼ˆ%ï¼‰
    'turnover_max': 20,          # æœ€å¤§æ¢æ‰‹ç‡ï¼ˆ%ï¼‰
    'volume_ratio_min': 1.5,     # æœ€å°æˆäº¤é‡å€æ•°

    # è‚¡ä»·ä½ç½®æ£€æŸ¥
    'check_price_position': True, # æ˜¯å¦æ£€æŸ¥è‚¡ä»·ä½ç½®
    'check_ma5': True,           # æ˜¯å¦æ£€æŸ¥5æ—¥å‡çº¿
    'check_ma10': True,          # æ˜¯å¦æ£€æŸ¥10æ—¥å‡çº¿

    # V4æ–°å¢ï¼šæ­¢æŸæ­¢ç›ˆå‚æ•°
    'stop_loss_pct': 5.0,        # æ­¢æŸç™¾åˆ†æ¯”ï¼ˆ%ï¼‰
    'stop_loss_ma': True,        # æ˜¯å¦ä½¿ç”¨5æ—¥å‡çº¿æ­¢æŸ
    'take_profit_min': 10.0,     # æœ€ä½æ­¢ç›ˆç™¾åˆ†æ¯”ï¼ˆ%ï¼‰
    'take_profit_max': 15.0,     # æœ€é«˜æ­¢ç›ˆç™¾åˆ†æ¯”ï¼ˆ%ï¼‰
}

# æ’é™¤å‰ç¼€ï¼ˆV4å®Œå–„ï¼šç¡®ä¿å½»åº•æ’é™¤ï¼‰
# 300: åˆ›ä¸šæ¿
# 301: åˆ›ä¸šæ¿
# 688: ç§‘åˆ›æ¿
# 8: åŒ—äº¤æ‰€
# 4: åŒ—äº¤æ‰€
# 920: åŒ—äº¤æ‰€
EXCLUDE_PREFIX = ['300', '301', '688', '8', '4', '920']

# V4æ–°å¢ï¼šæ’é™¤è‚¡ç¥¨åç§°ä¸­çš„é£é™©å…³é”®è¯
EXCLUDE_NAME_KEYWORDS = ['ST', r'\*ST', 'é€€', 'é€€æ•´ç†']

# ==================== å·¥å…·å‡½æ•° ====================

def api_call_with_retry(func, *args, **kwargs):
    """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
    for attempt in range(API_CONFIG['retry_times']):
        try:
            result = func(*args, **kwargs)
            time.sleep(API_CONFIG['request_delay'])
            return result
        except Exception as e:
            if attempt < API_CONFIG['retry_times'] - 1:
                print(f"  âš ï¸  APIè°ƒç”¨å¤±è´¥ï¼ˆç¬¬{attempt+1}æ¬¡å°è¯•ï¼‰: {e}")
                print(f"  â³  {API_CONFIG['retry_delay']}ç§’åé‡è¯•...")
                time.sleep(API_CONFIG['retry_delay'])
            else:
                print(f"  âŒ APIè°ƒç”¨å¤±è´¥ï¼ˆå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰: {e}")
                raise
    return None

def get_daily_data_batch(ts_codes, start_date, end_date):
    """åˆ†æ‰¹è·å–å†å²æ•°æ®ï¼Œé¿å…é¢‘ç‡é™åˆ¶"""
    all_data = []
    total = len(ts_codes)
    batch_size = API_CONFIG['batch_size']

    for i in range(0, total, batch_size):
        batch = ts_codes[i:i + batch_size]
        print(f"    - æ­£åœ¨è·å–ç¬¬{i+1}-{min(i+batch_size, total)}/{total}åªè‚¡ç¥¨çš„å†å²æ•°æ®ï¼ˆ{start_date} - {end_date}ï¼‰...")

        try:
            df = api_call_with_retry(
                pro.daily,
                ts_code=batch,
                start_date=start_date,
                end_date=end_date,
                limit=API_CONFIG['limit']
            )

            if df is not None and len(df) > 0:
                print(f"      âœ“ è·å–åˆ° {len(df)} æ¡æ•°æ®")
                all_data.append(df)
            else:
                print(f"      âš ï¸  è¯¥æ‰¹æ¬¡æ— æ•°æ®")
        except Exception as e:
            print(f"    âŒ è·å–æ‰¹æ¬¡æ•°æ®å¤±è´¥: {e}")
            continue

    if len(all_data) == 0:
        print(f"    âš ï¸  æ€»å…±è·å–åˆ° 0 æ¡å†å²æ•°æ®")
        return pd.DataFrame()

    print(f"    âœ“ æ€»å…±è·å–åˆ° {sum([len(d) for d in all_data])} æ¡å†å²æ•°æ®")
    return pd.concat(all_data, ignore_index=True)

def get_daily_basic_batch(ts_codes, trade_date):
    """è·å–æ¯æ—¥æŒ‡æ ‡ï¼ˆæ³¨æ„ï¼šTushareçš„daily_basicæ¥å£ä¸æ”¯æŒts_codeå‚æ•°ç­›é€‰ï¼‰"""
    print(f"    - æ­£åœ¨è·å–æ‰€æœ‰è‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡ï¼ˆä¸é™åˆ¶ts_codeï¼‰...")

    try:
        df = api_call_with_retry(
            pro.daily_basic,
            trade_date=trade_date,
            fields='ts_code,pe_ttm,total_mv,circ_mv,turnover_rate'
        )

        if df is None or len(df) == 0:
            print("    âš ï¸  æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()

        df_filtered = df[df['ts_code'].isin(ts_codes)]
        print(f"    - ä» {len(df)} åªè‚¡ç¥¨ä¸­ç­›é€‰å‡º {len(df_filtered)} åªç›®æ ‡è‚¡ç¥¨")
        return df_filtered

    except Exception as e:
        print(f"    âŒ è·å–æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def calculate_stop_loss_take_profit(df, df_hist):
    """
    V4æ–°å¢ï¼šè®¡ç®—æ­¢æŸä½å’Œæ­¢ç›ˆä½
    - æ­¢æŸä½ï¼š5æ—¥å‡çº¿ æˆ– -5%è·Œå¹…
    - æ­¢ç›ˆä½ï¼š10%-15%æ¶¨å¹…
    """
    print("\n  [6.1] è®¡ç®—æ­¢æŸæ­¢ç›ˆä½...")

    if len(df_hist) == 0:
        print("    - æ— å†å²æ•°æ®ï¼Œä½¿ç”¨å›ºå®šæ­¢æŸæ­¢ç›ˆç­–ç•¥ï¼ˆ5%æ­¢æŸï¼Œ10%-15%æ­¢ç›ˆï¼‰")
        # ä½¿ç”¨å›ºå®šæ­¢æŸæ­¢ç›ˆ
        df.loc[:, 'stop_loss'] = (df['close'] * (1 - SCREENING_PARAMS['stop_loss_pct'] / 100)).round(2)
        df.loc[:, 'stop_loss_type'] = f"{SCREENING_PARAMS['stop_loss_pct']}%æ­¢æŸ"
        df.loc[:, 'take_profit_min'] = (df['close'] * (1 + SCREENING_PARAMS['take_profit_min'] / 100)).round(2)
        df.loc[:, 'take_profit_max'] = (df['close'] * (1 + SCREENING_PARAMS['take_profit_max'] / 100)).round(2)
        df.loc[:, 'take_profit_target'] = (df['close'] * (1 + (SCREENING_PARAMS['take_profit_min'] + SCREENING_PARAMS['take_profit_max']) / 2 / 100)).round(2)
        print(f"    - å·²è®¡ç®— {len(df)} åªè‚¡ç¥¨çš„æ­¢æŸæ­¢ç›ˆä½ï¼ˆå›ºå®šç­–ç•¥ï¼‰")
        print(f"    - æ­¢æŸç­–ç•¥ï¼š{SCREENING_PARAMS['stop_loss_pct']}%æ­¢æŸ")
        print(f"    - æ­¢ç›ˆç­–ç•¥ï¼š{SCREENING_PARAMS['take_profit_min']}-{SCREENING_PARAMS['take_profit_max']}%")
        return df

    # æœ‰å†å²æ•°æ®æ—¶ï¼Œä½¿ç”¨5æ—¥å‡çº¿æ­¢æŸ
    df.loc[:, 'stop_loss_ma'] = df['ma5'].round(2)
    df.loc[:, 'stop_loss_pct'] = (df['close'] * (1 - SCREENING_PARAMS['stop_loss_pct'] / 100)).round(2)
    
    if SCREENING_PARAMS['stop_loss_ma']:
        df.loc[:, 'stop_loss'] = df[['stop_loss_ma', 'stop_loss_pct']].max(axis=1).round(2)
        df.loc[:, 'stop_loss_type'] = '5æ—¥å‡çº¿'
    else:
        df.loc[:, 'stop_loss'] = df['stop_loss_pct']
        df.loc[:, 'stop_loss_type'] = '5%æ­¢æŸ'

    # è®¡ç®—æ­¢ç›ˆä½ï¼ˆ10%-15%ï¼‰
    df.loc[:, 'take_profit_min'] = (df['close'] * (1 + SCREENING_PARAMS['take_profit_min'] / 100)).round(2)
    df.loc[:, 'take_profit_max'] = (df['close'] * (1 + SCREENING_PARAMS['take_profit_max'] / 100)).round(2)
    df.loc[:, 'take_profit_target'] = (df['close'] * (1 + (SCREENING_PARAMS['take_profit_min'] + SCREENING_PARAMS['take_profit_max']) / 2 / 100)).round(2)

    print(f"    - å·²è®¡ç®— {len(df)} åªè‚¡ç¥¨çš„æ­¢æŸæ­¢ç›ˆä½")
    print(f"    - æ­¢æŸç­–ç•¥ï¼š{'5æ—¥å‡çº¿' if SCREENING_PARAMS['stop_loss_ma'] else '5%æ­¢æŸ'}")
    print(f"    - æ­¢ç›ˆç­–ç•¥ï¼š{SCREENING_PARAMS['take_profit_min']}-{SCREENING_PARAMS['take_profit_max']}%")

    return df

# ==================== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ====================

def get_trade_cal():
    """è·å–æœ€è¿‘äº¤æ˜“æ—¥"""
    try:
        trade_cal = api_call_with_retry(
            pro.trade_cal,
            exchange='SSE',
            start_date=(datetime.now() - timedelta(days=10)).strftime('%Y%m%d')
        )

        if trade_cal is None:
            return None

        trade_cal = trade_cal[trade_cal.is_open == 1]
        if len(trade_cal) == 0:
            return None

        latest_date = trade_cal.iloc[-1]['cal_date']
        return latest_date
    except Exception as e:
        print(f"âŒ è·å–äº¤æ˜“æ—¥å¤±è´¥: {e}")
        return None


def check_price_position(df, df_hist):
    """æ£€æŸ¥è‚¡ä»·ä½ç½®ï¼ˆè¦æ±‚æ”¶ç›˜ä»·ç«™åœ¨5æ—¥å’Œ10æ—¥å‡çº¿ä¸Šæ–¹ï¼‰"""
    print("\n  [5.1] æ£€æŸ¥è‚¡ä»·ä½ç½®...")

    if len(df_hist) == 0 or not SCREENING_PARAMS['check_price_position']:
        print("    - è·³è¿‡è‚¡ä»·ä½ç½®æ£€æŸ¥")
        return df

    # è½¬æ¢æ—¥æœŸæ ¼å¼
    df_hist['trade_date'] = pd.to_datetime(df_hist['trade_date'], format='%Y%m%d')
    df_hist = df_hist.sort_values(['ts_code', 'trade_date'])

    # è®¡ç®—5æ—¥å’Œ10æ—¥å‡çº¿
    df_hist['ma5'] = df_hist.groupby('ts_code')['close'].rolling(5).mean().reset_index(0, drop=True)
    df_hist['ma10'] = df_hist.groupby('ts_code')['close'].rolling(10).mean().reset_index(0, drop=True)

    # è·å–æ¯åªè‚¡ç¥¨æœ€æ–°çš„å‡çº¿æ•°æ®
    latest_ma = df_hist.groupby('ts_code').last().reset_index()
    latest_ma = latest_ma[['ts_code', 'ma5', 'ma10']]

    # åˆå¹¶å‡çº¿æ•°æ®
    df = df.merge(latest_ma, on='ts_code', how='left')

    # æ£€æŸ¥è‚¡ä»·æ˜¯å¦ç«™åœ¨å‡çº¿ä¸Šæ–¹
    initial_count = len(df)

    if SCREENING_PARAMS['check_ma5']:
        df = df[df['close'] > df['ma5']]
        print(f"    - 5æ—¥å‡çº¿ç­›é€‰å: {len(df)} åª")

    if SCREENING_PARAMS['check_ma10']:
        df = df[df['close'] > df['ma10']]
        print(f"    - 10æ—¥å‡çº¿ç­›é€‰å: {len(df)} åª")

    filtered_count = initial_count - len(df)
    if filtered_count > 0:
        print(f"    - è‚¡ä»·ä½ç½®æ£€æŸ¥: è¿‡æ»¤ {filtered_count} åªé«˜ä½æ”¾é‡è‚¡ç¥¨")

    return df


def get_daily_screener():
    """
    ä¸»ç­›é€‰å‡½æ•°ï¼šé£é™©è¿‡æ»¤å‹é€‰è‚¡ï¼ˆV4ç»ˆæç‰ˆï¼‰
    """
    print("=" * 80)
    print("é€‰è‚¡Bç¨‹åº - é£é™©è¿‡æ»¤å‹é€‰è‚¡ï¼ˆV4ç»ˆæç‰ˆï¼‰")
    print("=" * 80)
    print(f"\nå½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nV4ç‰ˆæœ¬æ–°å¢åŠŸèƒ½ï¼š")
    print("  1. âœ… æ·»åŠ æ­¢æŸ/æ­¢ç›ˆå‚è€ƒï¼ˆ5æ—¥å‡çº¿æ­¢æŸã€10%-15%æ­¢ç›ˆï¼‰")
    print("  2. âœ… å®Œå–„STè‚¡æ’é™¤é€»è¾‘ï¼ˆè¦†ç›–STã€*STã€é€€ã€é€€æ•´ç†ï¼‰")
    print("  3. âœ… ç¡®ä¿å½»åº•æ’é™¤åˆ›ä¸šæ¿ã€ç§‘åˆ›æ¿ã€åŒ—äº¤æ‰€è‚¡ç¥¨")
    print("  4. âœ… æ·»åŠ è¯¦ç»†çš„æ“ä½œå»ºè®®å’Œé£é™©æç¤º")

    # è·å–æœ€è¿‘äº¤æ˜“æ—¥
    trade_date = get_trade_cal()
    if not trade_date:
        print("âŒ æœªèƒ½è·å–äº¤æ˜“æ—¥ï¼Œç¨‹åºé€€å‡ºã€‚")
        return pd.DataFrame()

    print(f"\näº¤æ˜“æ—¥: {trade_date}")

    # ==================== æ­¥éª¤1ï¼šåŸºç¡€è¿‡æ»¤ ====================
    print("\n[æ­¥éª¤1/7] æ­£åœ¨è¿›è¡ŒåŸºç¡€è¿‡æ»¤...")

    # 1.1 è·å–å½“æ—¥æ‰€æœ‰è‚¡ç¥¨æ•°æ®
    print("  - æ­£åœ¨è·å–å½“æ—¥è¡Œæƒ…æ•°æ®...")
    try:
        df_daily = api_call_with_retry(
            pro.daily,
            trade_date=trade_date,
            limit=API_CONFIG['limit']
        )

        if df_daily is None or len(df_daily) == 0:
            print("  âŒ è·å–è¡Œæƒ…æ•°æ®å¤±è´¥")
            return pd.DataFrame()

        print(f"  - è·å–åˆ° {len(df_daily)} åªè‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®")
    except Exception as e:
        print(f"  âŒ è·å–è¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

    # 1.2 è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    print("  - æ­£åœ¨è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
    try:
        stock_basic = api_call_with_retry(
            pro.stock_basic,
            exchange='',
            list_status='L',
            fields='ts_code,symbol,name,area,industry,list_date,market'
        )

        if stock_basic is None or len(stock_basic) == 0:
            print("  âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥")
            return pd.DataFrame()

        print(f"  - è·å–åˆ° {len(stock_basic)} åªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯")

        # ä¼˜åŒ–ï¼šå°†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è½¬æ¢ä¸ºå­—å…¸æ˜ å°„
        stock_basic_dict = stock_basic.set_index('ts_code')[['name', 'industry', 'list_date']].to_dict('index')
        print(f"  - å·²åˆ›å»ºè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å­—å…¸æ˜ å°„ï¼ˆ{len(stock_basic_dict)}æ¡è®°å½•ï¼‰")

    except Exception as e:
        print(f"  âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        return pd.DataFrame()

    # 1.3 V4å®Œå–„ï¼šè¿‡æ»¤æ’é™¤å‰ç¼€ï¼ˆç¡®ä¿å½»åº•æ’é™¤åˆ›ä¸šæ¿ã€ç§‘åˆ›æ¿ã€åŒ—äº¤æ‰€ï¼‰
    print("  - è¿‡æ»¤ç§‘åˆ›æ¿ã€åˆ›ä¸šæ¿ã€STè‚¡ã€åŒ—äº¤æ‰€...")
    df = df_daily.copy()
    df = df[~df['ts_code'].str[:3].isin(EXCLUDE_PREFIX)]
    print(f"    - è¿‡æ»¤å‰ç¼€åå‰©ä½™ {len(df)} åªè‚¡ç¥¨")

    # 1.4 V4æ–°å¢ï¼šè¿‡æ»¤è‚¡ç¥¨åç§°ä¸­çš„é£é™©å…³é”®è¯ï¼ˆSTã€*STã€é€€ã€é€€æ•´ç†ï¼‰
    print(f"  - è¿‡æ»¤é£é™©è‚¡ç¥¨ï¼ˆ{', '.join(EXCLUDE_NAME_KEYWORDS)}ï¼‰...")
    initial_count = len(df)
    df = df[~df['ts_code'].isin(stock_basic.index)]
    df['name'] = df['ts_code'].map(lambda x: stock_basic_dict.get(x, {}).get('name', ''))
    
    # æ£€æŸ¥è‚¡ç¥¨åç§°æ˜¯å¦åŒ…å«é£é™©å…³é”®è¯ï¼ˆä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼‰
    pattern = '|'.join([re.escape(keyword) for keyword in EXCLUDE_NAME_KEYWORDS])
    df = df[~df['name'].str.contains(pattern, na=False)]
    
    filtered_count = initial_count - len(df)
    if filtered_count > 0:
        print(f"    - è¿‡æ»¤é£é™©è‚¡ç¥¨å: {len(df)} åªè‚¡ç¥¨ï¼ˆå·²è¿‡æ»¤ {filtered_count} åªï¼‰")

    # 1.5 åˆå¹¶æ•°æ®
    print("  - åˆå¹¶è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
    df.loc[:, 'industry'] = df['ts_code'].map(lambda x: stock_basic_dict.get(x, {}).get('industry', ''))
    df.loc[:, 'list_date'] = df['ts_code'].map(lambda x: stock_basic_dict.get(x, {}).get('list_date', ''))

    # ==================== æ­¥éª¤2ï¼šä¸Šæ¶¨é—¨æ§›è¿‡æ»¤ ====================
    print("\n[æ­¥éª¤2/7] æ­£åœ¨è¿›è¡Œä¸Šæ¶¨é—¨æ§›è¿‡æ»¤...")

    print(f"  - æ¶¨å¹… >= {SCREENING_PARAMS['min_pct_chg']}%...")
    df = df[df['pct_chg'] >= SCREENING_PARAMS['min_pct_chg']]
    print(f"  - è¿‡æ»¤åå‰©ä½™ {len(df)} åªè‚¡ç¥¨")

    if len(df) == 0:
        print("  âš ï¸  æ²¡æœ‰è‚¡ç¥¨é€šè¿‡ä¸Šæ¶¨é—¨æ§›è¿‡æ»¤")
        return pd.DataFrame()

    # ==================== æ­¥éª¤3ï¼šä»·æ ¼åŒºé—´ç­›é€‰ ====================
    print("\n[æ­¥éª¤3/7] æ­£åœ¨è¿›è¡Œä»·æ ¼åŒºé—´ç­›é€‰...")

    print(f"  - ä»·æ ¼åŒºé—´ï¼š{SCREENING_PARAMS['price_min']}-{SCREENING_PARAMS['price_max']}å…ƒ...")
    df = df[(df['close'] >= SCREENING_PARAMS['price_min']) &
            (df['close'] <= SCREENING_PARAMS['price_max'])]
    print(f"  - è¿‡æ»¤åå‰©ä½™ {len(df)} åªè‚¡ç¥¨")

    if len(df) == 0:
        print("  âš ï¸  æ²¡æœ‰è‚¡ç¥¨é€šè¿‡ä»·æ ¼åŒºé—´ç­›é€‰")
        return pd.DataFrame()

    # ==================== æ­¥éª¤4ï¼šé£é™©æŒ‡æ ‡è¿‡æ»¤ ====================
    print("\n[æ­¥éª¤4/7] æ­£åœ¨è¿›è¡Œé£é™©æŒ‡æ ‡è¿‡æ»¤...")

    # 4.1 è·å–æ¯æ—¥æŒ‡æ ‡
    print("  - è·å–æ¯æ—¥æŒ‡æ ‡ï¼ˆåŒ…å«æ¢æ‰‹ç‡ï¼‰...")
    
    # åˆå§‹åŒ–å­—æ®µ
    df.loc[:, 'total_mv'] = df.get('total_mv', 0)
    df.loc[:, 'pe_ttm'] = df.get('pe_ttm', 0)
    df.loc[:, 'turnover_rate'] = df.get('turnover_rate', 0)

    try:
        df_daily_basic = get_daily_basic_batch(
            df['ts_code'].tolist(),
            trade_date
        )

        if df_daily_basic is not None and len(df_daily_basic) > 0:
            # é¢„å…ˆè½¬æ¢æ•°æ®ç±»å‹ä»¥é¿å… FutureWarningï¼ˆå‘é‡åŒ–æ“ä½œï¼‰
            cols_to_convert = [col for col in ['total_mv', 'pe_ttm', 'turnover_rate'] if col in df.columns]
            if cols_to_convert:
                df[cols_to_convert] = df[cols_to_convert].astype('float64')

            df = df.merge(df_daily_basic, on='ts_code', how='left', suffixes=('', '_new'))

            df.loc[:, 'total_mv'] = df['total_mv_new'].fillna(df['total_mv']).astype('float64')
            df.loc[:, 'pe_ttm'] = df['pe_ttm_new'].fillna(df['pe_ttm']).astype('float64')
            df.loc[:, 'turnover_rate'] = df['turnover_rate_new'].fillna(df['turnover_rate']).astype('float64')

            df = df.drop(columns=['total_mv_new', 'pe_ttm_new', 'turnover_rate_new'], errors='ignore')

            print(f"  - è·å–åˆ° {len(df_daily_basic)} åªè‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡")
        else:
            print("  âš ï¸  è·å–æ¯æ—¥æŒ‡æ ‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    except Exception as e:
        print(f"  âš ï¸  è·å–æ¯æ—¥æŒ‡æ ‡å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")

    # 4.2 è®¡ç®—å¸‚å€¼ï¼ˆäº¿ï¼‰
    df['total_mv'] = df['total_mv'] / 10000

    # 4.3 ä½¿ç”¨æ¢æ‰‹ç‡ç­›é€‰
    if 'turnover_rate' in df.columns:
        print(f"  - æ¢æ‰‹ç‡åŒºé—´ï¼š{SCREENING_PARAMS['turnover_min']}-{SCREENING_PARAMS['turnover_max']}%...")
        df = df[(df['turnover_rate'] >= SCREENING_PARAMS['turnover_min']) &
                (df['turnover_rate'] <= SCREENING_PARAMS['turnover_max'])]
        print(f"  - æ¢æ‰‹ç‡ç­›é€‰å: {len(df)} åªè‚¡ç¥¨")
    else:
        print("  âš ï¸  æœªè·å–åˆ°æ¢æ‰‹ç‡æ•°æ®ï¼Œè·³è¿‡æ¢æ‰‹ç‡ç­›é€‰")

    # 4.4 è®¡ç®—ä¸Šå¸‚å¤©æ•°
    df['list_date'] = pd.to_datetime(df['list_date'], format='%Y%m%d')
    df['list_days'] = (datetime.now() - df['list_date']).dt.days

    # 4.5 è¿‡æ»¤æ–°è‚¡
    print(f"  - ä¸Šå¸‚å¤©æ•° >= {SCREENING_PARAMS['min_list_days']}å¤©...")
    df = df[df['list_days'] >= SCREENING_PARAMS['min_list_days']]
    print(f"  - è¿‡æ»¤åå‰©ä½™ {len(df)} åªè‚¡ç¥¨")

    if len(df) == 0:
        print("  âš ï¸  æ²¡æœ‰è‚¡ç¥¨é€šè¿‡æ–°è‚¡è¿‡æ»¤")
        return pd.DataFrame()

    # ==================== æ­¥éª¤5ï¼šé¾™è™æ¦œé£é™©è¿‡æ»¤ ====================
    print("\n[æ­¥éª¤5/7] æ­£åœ¨è¿›è¡Œé¾™è™æ¦œé£é™©è¿‡æ»¤...")

    print("  - è·å–é¾™è™æ¦œæ•°æ®...")
    try:
        df_top = api_call_with_retry(
            pro.top_list,
            trade_date=trade_date
        )

        if df_top is not None and len(df_top) > 0:
            print(f"  - è·å–åˆ° {len(df_top)} æ¡é¾™è™æ¦œè®°å½•")

            if 'buy' in df_top.columns and 'sell' in df_top.columns:
                print(f"  - è¿‡æ»¤ä¹°ä¸€ç‹¬é£Ÿï¼ˆ>= {SCREENING_PARAMS['solo_buy_threshold']*100}%ï¼‰...")
                df_top_group = df_top.groupby('ts_code').agg({
                    'buy': 'sum',
                    'sell': 'sum'
                })
                df_top_group['solo_buy_ratio'] = df_top_group['buy'] / (df_top_group['buy'] + df_top_group['sell'])

                solo_buy_stocks = df_top_group[df_top_group['solo_buy_ratio'] >= SCREENING_PARAMS['solo_buy_threshold']].index.tolist()
                if len(solo_buy_stocks) > 0:
                    print(f"  - æ‹‰é»‘ {len(solo_buy_stocks)} åªä¹°ä¸€ç‹¬é£Ÿè‚¡ç¥¨")
                    df = df[~df['ts_code'].isin(solo_buy_stocks)]
                    print(f"  - è¿‡æ»¤åå‰©ä½™ {len(df)} åªè‚¡ç¥¨")
            else:
                print("  âš ï¸  é¾™è™æ¦œæ•°æ®ä¸åŒ…å«buy/sellå­—æ®µï¼Œè·³è¿‡ä¹°ä¸€ç‹¬é£Ÿè¿‡æ»¤")
        else:
            print("  - æ²¡æœ‰é¾™è™æ¦œæ•°æ®")
    except Exception as e:
        print(f"  âš ï¸  è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {e}")

    # ==================== æ­¥éª¤6ï¼šè®¡ç®—é«˜çº§æŒ‡æ ‡ï¼ˆV4å¢å¼ºï¼‰ ====================
    print("\n[æ­¥éª¤6/7] è®¡ç®—é«˜çº§æŒ‡æ ‡...")

    try:
        # è·å–è¿‡å»30æ—¥æ•°æ®è®¡ç®—æˆäº¤é‡å€æ•°ï¼ˆå»¶é•¿å‘¨æœŸä»¥ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
        start_date_5d = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')

        print("    - è·å–å†å²æ•°æ®è®¡ç®—æˆäº¤é‡å€æ•°...")
        df_hist = get_daily_data_batch(
            df['ts_code'].tolist(),
            start_date_5d,
            trade_date
        )

        print(f"    - è·å–åˆ° {len(df_hist)} æ¡å†å²æ•°æ®è®°å½•")

        # åˆå§‹åŒ–å¿…è¦å­—æ®µ
        if 'volume_ratio' not in df.columns:
            df['volume_ratio'] = 1.0
        if 'turnover_rate' not in df.columns:
            df['turnover_rate'] = 0.0
        if 'list_days' not in df.columns:
            df['list_date'] = pd.to_datetime(df['list_date'], format='%Y%m%d')
            df['list_days'] = (datetime.now() - df['list_date']).dt.days

        if len(df_hist) > 0:
            # è®¡ç®—5æ—¥å¹³å‡æˆäº¤é‡
            df_hist = df_hist.sort_values(['ts_code', 'trade_date'])
            df_hist_5d = df_hist.groupby('ts_code')['vol'].rolling(5).mean().reset_index()
            df_hist_5d.columns = ['ts_code', 'vol_5d']
            df_hist_5d = df_hist_5d.dropna().groupby('ts_code').last()

            df = df.merge(df_hist_5d[['vol_5d']], on='ts_code', how='left')

            # è®¡ç®—æˆäº¤é‡å€æ•°
            df['volume_ratio'] = df['vol'] / df['vol_5d']
            df['volume_ratio'] = df['volume_ratio'].fillna(1.0)

            # æˆäº¤é‡å€æ•°ç­›é€‰
            print(f"    - æˆäº¤é‡å€æ•° >= {SCREENING_PARAMS['volume_ratio_min']}")
            df = df[df['volume_ratio'] >= SCREENING_PARAMS['volume_ratio_min']]
            print(f"    - æˆäº¤é‡å€æ•°ç­›é€‰å: {len(df)} åª")

        # æ£€æŸ¥è‚¡ä»·ä½ç½®
        df = check_price_position(df, df_hist)

        # V4æ–°å¢ï¼šè®¡ç®—æ­¢æŸæ­¢ç›ˆä½
        df = calculate_stop_loss_take_profit(df, df_hist)

    except Exception as e:
        print(f"  âš ï¸  è®¡ç®—é«˜çº§æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        print(f"  â­ï¸  è·³è¿‡é«˜çº§æŒ‡æ ‡è®¡ç®—ï¼Œç»§ç»­ä½¿ç”¨åŸºç¡€ç­›é€‰ç»“æœ")

    # ==================== æ­¥éª¤7ï¼šè¾“å‡ºç»“æœï¼ˆV4å¢å¼ºï¼‰ ====================
    print(f"\nç­›é€‰å®Œæˆï¼Œå…± {len(df)} åªè‚¡ç¥¨")

    if len(df) == 0:
        print("\n" + "="*80)
        print("ç­›é€‰ç»“æœï¼šæœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        print("="*80)
        print("\nè¿™æ˜¯æ­£å¸¸çš„ï¼ç©ºä»“æ˜¯å®Œå…¨æ­£ç¡®çš„ç»“æœã€‚")
        print("ä¸è¦ä¸ºäº†ä¹°è‚¡ç¥¨è€Œé™ä½æ ‡å‡†ã€‚")
        print("="*80)
        return pd.DataFrame()

    # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å­—æ®µéƒ½å­˜åœ¨
    required_cols = ['ts_code', 'name', 'industry', 'close', 'pct_chg',
                     'volume_ratio', 'turnover_rate', 'total_mv', 'pe_ttm', 'list_days']
    for col in required_cols:
        if col not in df.columns:
            print(f"  âš ï¸  ç¼ºå°‘å­—æ®µ {col}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            if col == 'volume_ratio':
                df[col] = 1.0
            elif col == 'turnover_rate':
                df[col] = 0.0
            elif col == 'list_days':
                df[col] = 999
            else:
                df[col] = 0

    # V4æ–°å¢ï¼šç¡®ä¿æ­¢æŸæ­¢ç›ˆå­—æ®µå­˜åœ¨
    if 'stop_loss' not in df.columns:
        df['stop_loss'] = df['close'] * 0.95
    if 'stop_loss_type' not in df.columns:
        df['stop_loss_type'] = '5%æ­¢æŸ'
    if 'take_profit_min' not in df.columns:
        df['take_profit_min'] = df['close'] * 1.10
    if 'take_profit_max' not in df.columns:
        df['take_profit_max'] = df['close'] * 1.15
    if 'take_profit_target' not in df.columns:
        df['take_profit_target'] = df['close'] * 1.125

    # é€‰æ‹©è¾“å‡ºå­—æ®µï¼ˆV4æ–°å¢ï¼šåŒ…å«æ­¢æŸæ­¢ç›ˆï¼‰
    output_cols = ['ts_code', 'name', 'industry', 'close', 'pct_chg',
                   'volume_ratio', 'turnover_rate', 'total_mv', 'pe_ttm', 'list_days',
                   'stop_loss', 'stop_loss_type', 'take_profit_min', 'take_profit_max', 'take_profit_target']

    df_output = df[output_cols].copy()
    df_output.columns = ['ä»£ç ', 'åç§°', 'è¡Œä¸šæ¿å—', 'æ”¶ç›˜ä»·', 'æ¶¨å¹…(%)',
                         'æˆäº¤é‡å€æ•°', 'æ¢æ‰‹ç‡(%)', 'å¸‚å€¼(äº¿)', 'PE(TTM)', 'ä¸Šå¸‚å¤©æ•°',
                         'æ­¢æŸä»·', 'æ­¢æŸç±»å‹', 'æ­¢ç›ˆä»·(æœ€ä½)', 'æ­¢ç›ˆä»·(æœ€é«˜)', 'æ­¢ç›ˆä»·(å‚è€ƒ)']

    # æ’åºï¼šæŒ‰æ¶¨å¹…é™åº
    df_output = df_output.sort_values('æ¶¨å¹…(%)', ascending=False)

    print("\n" + "="*80)
    print("ç­›é€‰ç»“æœ")
    print("="*80)
    print(f"\né€‰è‚¡æ•°é‡: {len(df_output)} åª\n")

    print(df_output.to_string(index=False))

    # ä¿å­˜åˆ°CSV
    df_output.to_csv(OUTPUT_FILE, index=False, encoding='utf_8_sig')
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_FILE}")
    print("="*80)

    # V4æ–°å¢ï¼šè¾“å‡ºæ“ä½œå»ºè®®
    print("\n" + "="*80)
    print("æ“ä½œå»ºè®®")
    print("="*80)
    print(f"\nğŸ“Œ ä¹°å…¥æ—¶æœºï¼š")
    print(f"  - å»ºè®®å¼€ç›˜åè§‚å¯Ÿï¼Œè‹¥è‚¡ä»·å›è°ƒåˆ°æ”¯æ’‘ä½å¯è€ƒè™‘ä¹°å…¥")
    print(f"  - å»ºè®®åˆ†æ‰¹å»ºä»“ï¼Œæ§åˆ¶å•åªè‚¡ç¥¨ä»“ä½ä¸è¶…è¿‡æ€»èµ„é‡‘çš„10%")
    
    print(f"\nğŸ“Œ æ­¢æŸç­–ç•¥ï¼š")
    print(f"  - æ­¢æŸä½ï¼š{'5æ—¥å‡çº¿' if SCREENING_PARAMS['stop_loss_ma'] else '5%æ­¢æŸ'}")
    print(f"  - ä¸€æ—¦è·Œç ´æ­¢æŸä½ï¼Œåšå†³æ­¢æŸï¼Œä¸è¦æŠ±æœ‰å¹»æƒ³")
    print(f"  - æ­¢æŸæ˜¯ä¿å‘½çš„ï¼Œä¸¥æ ¼æ‰§è¡Œï¼")
    
    print(f"\nğŸ“Œ æ­¢ç›ˆç­–ç•¥ï¼š")
    print(f"  - ç¬¬ä¸€æ­¢ç›ˆä½ï¼š{SCREENING_PARAMS['take_profit_min']}%ï¼ˆå¯å‡ä»“50%ï¼‰")
    print(f"  - ç¬¬äºŒæ­¢ç›ˆä½ï¼š{SCREENING_PARAMS['take_profit_max']}%ï¼ˆå¯å‡ä»“è‡³20%ï¼‰")
    print(f"  - å‰©ä½™ä»“ä½å¯è·Ÿè¸ªè¶‹åŠ¿ï¼Œè®¾ç½®ç§»åŠ¨æ­¢æŸ")
    
    print(f"\nğŸ“Œ é£é™©æç¤ºï¼š")
    print(f"  - æœ¬ç­›é€‰ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")
    print(f"  - è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…")
    print(f"  - è¯·æ ¹æ®è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›ç†æ€§æŠ•èµ„")
    print(f"  - ä¸¥æ ¼æ‰§è¡Œæ­¢æŸæ­¢ç›ˆçºªå¾‹")
    
    print(f"\nğŸ“Œ èµ„é‡‘ç®¡ç†ï¼š")
    print(f"  - å»ºè®®æ€»ä»“ä½æ§åˆ¶åœ¨30%-50%")
    print(f"  - å•åªè‚¡ç¥¨ä»“ä½ä¸è¶…è¿‡10%")
    print(f"  - ä¿ç•™30%ç°é‡‘åº”å¯¹çªå‘æƒ…å†µ")
    
    print("="*80)

    return df_output


def main():
    """ä¸»å‡½æ•°"""
    get_daily_screener()


if __name__ == '__main__':
    main()
