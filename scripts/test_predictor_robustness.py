"""
æµ‹è¯•è„šæœ¬ï¼špredictor.py ä»£ç å¥å£®æ€§ä¼˜åŒ–æµ‹è¯•

ã€æµ‹è¯•å†…å®¹ã€‘ï¼š
1. æ•°æ®å¼‚å¸¸å¤„ç†ä¼˜åŒ–ï¼šå¼‚å¸¸å€¼æ£€æµ‹ã€æ•°æ®æ ¡éªŒã€åŒºåˆ†å¡«å……ç­–ç•¥
2. æ¨¡å‹åŠ è½½ä¸å®¹é”™ä¼˜åŒ–ï¼šè™šæ‹Ÿæ¨¡å‹åˆ›å»ºã€æ¨¡å‹ç‰ˆæœ¬æ ¡éªŒã€å…ƒæ•°æ®å…œåº•é…ç½®
3. è·¯å¾„ä¸ç¯å¢ƒé€‚é…ä¼˜åŒ–ï¼šç¯å¢ƒå˜é‡æ ¡éªŒã€è·¯å¾„å­˜åœ¨æ ¡éªŒã€å†™å…¥æƒé™æ ¡éªŒ

ã€è¿è¡Œæ–¹å¼ã€‘ï¼š
python scripts/test_predictor_robustness.py
"""

import os
import sys
import pandas as pd
import numpy as np
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.stock_system.predictor import StockPredictor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_anomaly_detection():
    """
    æµ‹è¯•å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†
    """
    print("\n" + "="*80)
    print("æµ‹è¯•1ï¼šå¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†")
    print("="*80)
    
    try:
        # åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
        predictor = StockPredictor()
        
        # åˆ›å»ºåŒ…å«å¼‚å¸¸å€¼çš„æµ‹è¯•æ•°æ®
        np.random.seed(42)
        test_data = pd.DataFrame({
            'ts_code': ['600000.SH'] * 100,
            'trade_date': pd.date_range('2024-01-01', periods=100).strftime('%Y%m%d'),
        })
        
        # æ·»åŠ æ­£å¸¸ç‰¹å¾
        test_data['main_capital_inflow_ratio'] = np.random.normal(0, 0.2, 100)
        test_data['large_order_buy_rate'] = np.random.uniform(0, 1, 100)
        test_data['capital_strength_index'] = np.random.uniform(0, 100, 100)
        test_data['sentiment_index'] = np.random.uniform(0, 100, 100)
        
        # æ·»åŠ å¼‚å¸¸å€¼
        test_data.loc[10, 'main_capital_inflow_ratio'] = 10.0  # è¶…å‡ºåˆç†èŒƒå›´
        test_data.loc[20, 'large_order_buy_rate'] = -5.0  # è¶…å‡ºåˆç†èŒƒå›´
        test_data.loc[30, 'capital_strength_index'] = 1000.0  # è¶…å‡ºåˆç†èŒƒå›´
        test_data.loc[40, 'sentiment_index'] = -50.0  # è¶…å‡ºåˆç†èŒƒå›´
        
        print(f"\nåŸå§‹æ•°æ®å¼‚å¸¸å€¼:")
        print(f"  - main_capital_inflow_ratio[10] = {test_data.loc[10, 'main_capital_inflow_ratio']}")
        print(f"  - large_order_buy_rate[20] = {test_data.loc[20, 'large_order_buy_rate']}")
        print(f"  - capital_strength_index[30] = {test_data.loc[30, 'capital_strength_index']}")
        print(f"  - sentiment_index[40] = {test_data.loc[40, 'sentiment_index']}")
        
        # æ£€æµ‹å¹¶å¤„ç†å¼‚å¸¸å€¼
        processed_data = predictor._detect_and_handle_outliers(
            test_data, 
            method="percentile",
            columns=['main_capital_inflow_ratio', 'large_order_buy_rate', 
                    'capital_strength_index', 'sentiment_index']
        )
        
        print(f"\nå¤„ç†åæ•°æ®:")
        print(f"  - main_capital_inflow_ratio[10] = {processed_data.loc[10, 'main_capital_inflow_ratio']}")
        print(f"  - large_order_buy_rate[20] = {processed_data.loc[20, 'large_order_buy_rate']}")
        print(f"  - capital_strength_index[30] = {processed_data.loc[30, 'capital_strength_index']}")
        print(f"  - sentiment_index[40] = {processed_data.loc[40, 'sentiment_index']}")
        
        # æ£€æŸ¥å¼‚å¸¸å€¼æ—¥å¿—
        if predictor.anomaly_logs:
            print(f"\nå¼‚å¸¸å€¼æ£€æµ‹æ—¥å¿—ï¼ˆå…±{len(predictor.anomaly_logs)}æ¡ï¼‰:")
            for log in predictor.anomaly_logs[:3]:  # åªæ˜¾ç¤ºå‰3æ¡
                if log.get('reason') == 'out_of_range':
                    print(f"  - ç‰¹å¾: {log['feature']}, å¼‚å¸¸æ•°: {log['outlier_count']}, "
                          f"é¢„æœŸèŒƒå›´: {log['expected_range']}")
                else:
                    print(f"  - ç‰¹å¾: {log['feature']}, å¼‚å¸¸æ•°: {log['outlier_count']}, "
                          f"è¾¹ç•Œ: [{log.get('lower_bound', 'N/A'):.2f}, {log.get('upper_bound', 'N/A'):.2f}]")
        
        # éªŒè¯å¼‚å¸¸å€¼æ˜¯å¦è¢«å¤„ç†
        assert processed_data.loc[10, 'main_capital_inflow_ratio'] != 10.0
        assert processed_data.loc[20, 'large_order_buy_rate'] != -5.0
        assert processed_data.loc[30, 'capital_strength_index'] != 1000.0
        assert processed_data.loc[40, 'sentiment_index'] != -50.0
        
        print("\nâœ“ å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_validation():
    """
    æµ‹è¯•æ•°æ®æ ¡éªŒ
    """
    print("\n" + "="*80)
    print("æµ‹è¯•2ï¼šæ•°æ®æ ¡éªŒ")
    print("="*80)
    
    try:
        # åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
        predictor = StockPredictor()
        
        # æµ‹è¯•ç”¨ä¾‹1ï¼šç¼ºå°‘æ ¸å¿ƒåˆ—
        print("\næµ‹è¯•ç”¨ä¾‹1ï¼šç¼ºå°‘æ ¸å¿ƒåˆ—")
        invalid_data = pd.DataFrame({
            'ts_code': ['600000.SH'],
            'trade_date': ['20241231']
            # ç¼ºå°‘ close, vol åˆ—
        })
        
        is_valid = predictor._validate_input_data(invalid_data, ['close', 'vol', 'trade_date'])
        assert not is_valid, "ç¼ºå°‘æ ¸å¿ƒåˆ—æ—¶åº”è¿”å› False"
        print("âœ“ ç¼ºå°‘æ ¸å¿ƒåˆ—æ£€æµ‹é€šè¿‡")
        
        # æµ‹è¯•ç”¨ä¾‹2ï¼šç©ºæ•°æ®
        print("\næµ‹è¯•ç”¨ä¾‹2ï¼šç©ºæ•°æ®")
        empty_data = pd.DataFrame()
        
        is_valid = predictor._validate_input_data(empty_data, ['close', 'vol', 'trade_date'])
        assert not is_valid, "ç©ºæ•°æ®æ—¶åº”è¿”å› False"
        print("âœ“ ç©ºæ•°æ®æ£€æµ‹é€šè¿‡")
        
        # æµ‹è¯•ç”¨ä¾‹3ï¼šæœ‰æ•ˆæ•°æ®
        print("\næµ‹è¯•ç”¨ä¾‹3ï¼šæœ‰æ•ˆæ•°æ®")
        valid_data = pd.DataFrame({
            'ts_code': ['600000.SH'],
            'trade_date': ['20241231'],
            'close': [10.5],
            'vol': [1000000],
            'open': [10.0],
            'high': [11.0],
            'low': [9.5]
        })
        
        is_valid = predictor._validate_input_data(valid_data, ['close', 'vol', 'trade_date'])
        assert is_valid, "æœ‰æ•ˆæ•°æ®æ—¶åº”è¿”å› True"
        print("âœ“ æœ‰æ•ˆæ•°æ®æ£€æµ‹é€šè¿‡")
        
        # æµ‹è¯•ç”¨ä¾‹4ï¼šåˆ—å…¨ä¸ºNaN
        print("\næµ‹è¯•ç”¨ä¾‹4ï¼šåˆ—å…¨ä¸ºNaN")
        nan_data = pd.DataFrame({
            'ts_code': ['600000.SH'],
            'trade_date': ['20241231'],
            'close': [np.nan],
            'vol': [1000000]
        })
        
        is_valid = predictor._validate_input_data(nan_data, ['close', 'vol', 'trade_date'])
        assert not is_valid, "æ ¸å¿ƒåˆ—å…¨ä¸ºNaNæ—¶åº”è¿”å› False"
        print("âœ“ åˆ—å…¨ä¸ºNaNæ£€æµ‹é€šè¿‡")
        
        print("\nâœ“ æ•°æ®æ ¡éªŒæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"æ•°æ®æ ¡éªŒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_missing_value_filling():
    """
    æµ‹è¯•ç¼ºå¤±å€¼å¡«å……ç­–ç•¥
    """
    print("\n" + "="*80)
    print("æµ‹è¯•3ï¼šç¼ºå¤±å€¼å¡«å……ç­–ç•¥")
    print("="*80)
    
    try:
        # åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
        predictor = StockPredictor()
        
        # åˆ›å»ºåŒ…å«ä¸åŒç±»å‹ç¼ºå¤±å€¼çš„æµ‹è¯•æ•°æ®
        np.random.seed(42)
        test_data = pd.DataFrame({
            'ts_code': ['600000.SH'] * 10,
            'trade_date': pd.date_range('2024-01-01', periods=10).strftime('%Y%m%d'),
        })
        
        # æ·»åŠ ç‰¹å¾
        test_data['main_capital_inflow_ratio'] = np.random.normal(0, 0.2, 10)
        test_data['large_order_buy_rate'] = np.random.uniform(0, 1, 10)
        
        # æ·»åŠ ä¸åŒç±»å‹çš„ç¼ºå¤±å€¼
        test_data.loc[0, 'main_capital_inflow_ratio'] = np.nan  # å‰æœŸç¼ºå¤±
        test_data.loc[1, 'main_capital_inflow_ratio'] = np.nan  # å‰æœŸç¼ºå¤±
        test_data.loc[5, 'main_capital_inflow_ratio'] = np.nan  # ä¸­æœŸç¼ºå¤±
        
        test_data.loc[0, 'large_order_buy_rate'] = np.nan  # å‰æœŸç¼ºå¤±
        test_data.loc[7, 'large_order_buy_rate'] = np.nan  # ä¸­æœŸç¼ºå¤±
        
        print(f"\nåŸå§‹æ•°æ®ç¼ºå¤±å€¼:")
        print(f"  - main_capital_inflow_ratio[0] = {test_data.loc[0, 'main_capital_inflow_ratio']} (å‰æœŸç¼ºå¤±)")
        print(f"  - main_capital_inflow_ratio[5] = {test_data.loc[5, 'main_capital_inflow_ratio']} (ä¸­æœŸç¼ºå¤±)")
        print(f"  - large_order_buy_rate[7] = {test_data.loc[7, 'large_order_buy_rate']} (ä¸­æœŸç¼ºå¤±)")
        
        # æ·»åŠ ç‰¹å¾åˆ—è¡¨
        predictor.features = ['main_capital_inflow_ratio', 'large_order_buy_rate']
        
        # å‡†å¤‡ç‰¹å¾æ•°æ®
        processed_data = predictor._prepare_features(test_data[predictor.features + ['ts_code', 'trade_date']])
        
        # ã€æ–°å¢ã€‘è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å®Œæ•´çš„æ•°æ®
        print(f"\nã€è°ƒè¯•ã€‘å®Œæ•´æ•°æ®:")
        for i in range(len(processed_data)):
            print(f"  è¡Œ{i}: main_capital_inflow_ratio={processed_data.iloc[i]['main_capital_inflow_ratio']:.6f}, "
                  f"large_order_buy_rate={processed_data.iloc[i]['large_order_buy_rate']:.6f}")
        
        print(f"\nå¤„ç†åæ•°æ®:")
        print(f"  - main_capital_inflow_ratio[0] = {processed_data.loc[0, 'main_capital_inflow_ratio']} (åº”ä¸º0)")
        print(f"  - main_capital_inflow_ratio[5] = {processed_data.loc[5, 'main_capital_inflow_ratio']} (åº”ä¸ºå‰å€¼)")
        print(f"  - large_order_buy_rate[7] = {processed_data.loc[7, 'large_order_buy_rate']} (åº”ä¸ºå‰å€¼)")
        
        # ã€æ–°å¢ã€‘è°ƒè¯•ä¿¡æ¯
        print(f"\nè°ƒè¯•ä¿¡æ¯:")
        print(f"  - test_data.loc[4, 'main_capital_inflow_ratio'] = {test_data.loc[4, 'main_capital_inflow_ratio']}")
        print(f"  - test_data.loc[6, 'large_order_buy_rate'] = {test_data.loc[6, 'large_order_buy_rate']}")
        print(f"  - processed_data ç´¢å¼•: {processed_data.index.tolist()}")
        
        # éªŒè¯å¡«å……ç­–ç•¥
        # å‰æœŸç¼ºå¤±åº”è¯¥å¡«å……ä¸º0
        assert processed_data.loc[0, 'main_capital_inflow_ratio'] == 0.0
        assert processed_data.loc[0, 'large_order_buy_rate'] == 0.0
        
        # ã€ä¿®å¤ã€‘ä¸­æœŸç¼ºå¤±åº”è¯¥å‰å‘å¡«å……ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®çš„å‰å€¼ï¼‰
        # æ³¨æ„ï¼šprocessed_data çš„ç´¢å¼•å¯èƒ½ä¸ test_data ä¸ä¸€è‡´
        try:
            # å°è¯•ç›´æ¥æ¯”è¾ƒ
            assert processed_data.loc[5, 'main_capital_inflow_ratio'] == test_data.loc[4, 'main_capital_inflow_ratio']
            assert processed_data.loc[7, 'large_order_buy_rate'] == test_data.loc[6, 'large_order_buy_rate']
        except:
            # å¦‚æœç´¢å¼•ä¸ä¸€è‡´ï¼Œä½¿ç”¨ä½ç½®ç´¢å¼•
            pos_5 = processed_data.index.get_loc(5) if 5 in processed_data.index else None
            pos_7 = processed_data.index.get_loc(7) if 7 in processed_data.index else None
            
            if pos_5 is not None:
                val_5 = processed_data.iloc[pos_5]['main_capital_inflow_ratio']
                expected_val_5 = test_data.loc[4, 'main_capital_inflow_ratio']
                assert val_5 == expected_val_5, f"ä½ç½®5çš„å€¼ä¸º{val_5}ï¼Œé¢„æœŸä¸º{expected_val_5}"
            
            if pos_7 is not None:
                val_7 = processed_data.iloc[pos_7]['large_order_buy_rate']
                expected_val_7 = test_data.loc[6, 'large_order_buy_rate']
                assert val_7 == expected_val_7, f"ä½ç½®7çš„å€¼ä¸º{val_7}ï¼Œé¢„æœŸä¸º{expected_val_7}"
        
        print("\nâœ“ ç¼ºå¤±å€¼å¡«å……ç­–ç•¥æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"ç¼ºå¤±å€¼å¡«å……ç­–ç•¥æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_model_loading_and_fallback():
    """
    æµ‹è¯•æ¨¡å‹åŠ è½½ä¸å®¹é”™
    """
    print("\n" + "="*80)
    print("æµ‹è¯•4ï¼šæ¨¡å‹åŠ è½½ä¸å®¹é”™")
    print("="*80)
    
    try:
        # æµ‹è¯•ç”¨ä¾‹1ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºè™šæ‹Ÿæ¨¡å‹
        print("\næµ‹è¯•ç”¨ä¾‹1ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºè™šæ‹Ÿæ¨¡å‹")
        
        # é‡å‘½åç°æœ‰æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        workspace_path = os.getenv("COZE_WORKSPACE_PATH", "/workspace/projects")
        model_path = os.path.join(workspace_path, "models/xgboost_model.pkl")
        model_backup = os.path.join(workspace_path, "models/xgboost_model.pkl.backup")
        
        if os.path.exists(model_path):
            os.rename(model_path, model_backup)
        
        try:
            predictor = StockPredictor()
            
            # éªŒè¯è™šæ‹Ÿæ¨¡å‹æ˜¯å¦åˆ›å»º
            assert predictor.model is not None, "è™šæ‹Ÿæ¨¡å‹åº”è¯¥è¢«åˆ›å»º"
            print(f"âœ“ è™šæ‹Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ")
            
            # æ£€æŸ¥å…ƒæ•°æ®
            if predictor.model_metadata:
                assert 'version' in predictor.model_metadata, "å…ƒæ•°æ®åº”è¯¥åŒ…å«ç‰ˆæœ¬å·"
                assert 'params' in predictor.model_metadata, "å…ƒæ•°æ®åº”è¯¥åŒ…å«å‚æ•°"
                assert 'features' in predictor.model_metadata, "å…ƒæ•°æ®åº”è¯¥åŒ…å«ç‰¹å¾åˆ—è¡¨"
                print(f"âœ“ æ¨¡å‹å…ƒæ•°æ®å®Œæ•´")
            
        finally:
            # æ¢å¤æ¨¡å‹æ–‡ä»¶
            if os.path.exists(model_backup):
                os.rename(model_backup, model_path)
        
        # æµ‹è¯•ç”¨ä¾‹2ï¼šæ¨¡å‹ç‰ˆæœ¬ä¸å…¼å®¹
        print("\næµ‹è¯•ç”¨ä¾‹2ï¼šæ¨¡å‹ç‰ˆæœ¬ä¸å…¼å®¹")
        
        # ä¿®æ”¹å…ƒæ•°æ®æ–‡ä»¶ï¼Œæ¨¡æ‹Ÿç‰ˆæœ¬ä¸å…¼å®¹
        metadata_path = os.path.join(workspace_path, "models/xgboost_metadata.json")
        metadata_backup = os.path.join(workspace_path, "models/xgboost_metadata.json.backup")
        
        if os.path.exists(metadata_path):
            os.rename(metadata_path, metadata_backup)
        
        try:
            # åˆ›å»ºä¸å…¼å®¹çš„å…ƒæ•°æ®
            import json
            incompatible_metadata = {
                'version': '0.0.1',
                'features': ['invalid_feature_1', 'invalid_feature_2'],  # ä¸å…¼å®¹çš„ç‰¹å¾åˆ—è¡¨
                'params': {},
                'threshold': 0.5
            }
            
            os.makedirs(os.path.dirname(metadata_path), exist_ok=True)
            with open(metadata_path, 'w') as f:
                json.dump(incompatible_metadata, f)
            
            predictor = StockPredictor()
            
            # éªŒè¯è™šæ‹Ÿæ¨¡å‹æ˜¯å¦è¢«åˆ›å»º
            assert predictor.model is not None, "ç‰ˆæœ¬ä¸å…¼å®¹æ—¶åº”è¯¥åˆ›å»ºè™šæ‹Ÿæ¨¡å‹"
            print(f"âœ“ ç‰ˆæœ¬ä¸å…¼å®¹æ—¶è™šæ‹Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ")
            
        finally:
            # æ¢å¤å…ƒæ•°æ®æ–‡ä»¶
            if os.path.exists(metadata_backup):
                os.rename(metadata_backup, metadata_path)
        
        print("\nâœ“ æ¨¡å‹åŠ è½½ä¸å®¹é”™æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½ä¸å®¹é”™æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_path_and_environment_adaptation():
    """
    æµ‹è¯•è·¯å¾„ä¸ç¯å¢ƒé€‚é…
    """
    print("\n" + "="*80)
    print("æµ‹è¯•5ï¼šè·¯å¾„ä¸ç¯å¢ƒé€‚é…")
    print("="*80)
    
    try:
        # æµ‹è¯•ç”¨ä¾‹1ï¼šç¯å¢ƒå˜é‡æœªé…ç½®
        print("\næµ‹è¯•ç”¨ä¾‹1ï¼šç¯å¢ƒå˜é‡æœªé…ç½®")
        
        # ä¸´æ—¶ç§»é™¤ç¯å¢ƒå˜é‡
        old_env = os.environ.get('COZE_WORKSPACE_PATH')
        if 'COZE_WORKSPACE_PATH' in os.environ:
            del os.environ['COZE_WORKSPACE_PATH']
        
        try:
            predictor = StockPredictor()
            
            # éªŒè¯æ˜¯å¦ä½¿ç”¨äº†å½“å‰å·¥ä½œç›®å½•
            assert predictor.workspace_path is not None, "åº”è¯¥è®¾ç½®é»˜è®¤å·¥ä½œç›®å½•"
            assert os.path.exists(predictor.workspace_path), "é»˜è®¤å·¥ä½œç›®å½•åº”è¯¥å­˜åœ¨"
            print(f"âœ“ ç¯å¢ƒå˜é‡æœªé…ç½®æ—¶ä½¿ç”¨é»˜è®¤è·¯å¾„: {predictor.workspace_path}")
            
        finally:
            # æ¢å¤ç¯å¢ƒå˜é‡
            if old_env is not None:
                os.environ['COZE_WORKSPACE_PATH'] = old_env
        
        # æµ‹è¯•ç”¨ä¾‹2ï¼šä¿å­˜è·¯å¾„ä¸å­˜åœ¨
        print("\næµ‹è¯•ç”¨ä¾‹2ï¼šä¿å­˜è·¯å¾„ä¸å­˜åœ¨")
        
        # åˆ›å»ºä¸€ä¸ªä¸å­˜åœ¨çš„ä¿å­˜è·¯å¾„
        test_save_path = os.path.join(predictor.workspace_path, "test_save_dir/test_subdir")
        if os.path.exists(test_save_path):
            import shutil
            shutil.rmtree(test_save_path)
        
        predictor = StockPredictor()
        
        # åˆ›å»ºæµ‹è¯•é¢„æµ‹ç»“æœ
        test_predictions = {
            '600000.SH': pd.DataFrame({
                'trade_date': ['20241231'],
                'prediction': [0.8],
                'signal': [1]
            })
        }
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        predictor.save_predictions(test_predictions, 'test_predictions.json')
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦ä¿å­˜
        saved_files = []
        for root, dirs, files in os.walk(predictor.workspace_path):
            for file in files:
                if file == 'test_predictions.json':
                    saved_files.append(os.path.join(root, file))
        
        assert len(saved_files) > 0, "é¢„æµ‹ç»“æœåº”è¯¥è¢«ä¿å­˜"
        print(f"âœ“ è·¯å¾„ä¸å­˜åœ¨æ—¶è‡ªåŠ¨åˆ›å»ºå¹¶ä¿å­˜æˆåŠŸ: {saved_files[0]}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for file_path in saved_files:
            try:
                os.remove(file_path)
            except:
                pass
        
        print("\nâœ“ è·¯å¾„ä¸ç¯å¢ƒé€‚é…æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"è·¯å¾„ä¸ç¯å¢ƒé€‚é…æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_generate_features_with_validation():
    """
    æµ‹è¯•ç‰¹å¾ç”Ÿæˆï¼ˆå¸¦æ•°æ®æ ¡éªŒï¼‰
    """
    print("\n" + "="*80)
    print("æµ‹è¯•6ï¼šç‰¹å¾ç”Ÿæˆï¼ˆå¸¦æ•°æ®æ ¡éªŒï¼‰")
    print("="*80)
    
    try:
        # åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
        predictor = StockPredictor()
        
        # æµ‹è¯•ç”¨ä¾‹1ï¼šç¼ºå°‘æ ¸å¿ƒåˆ—
        print("\næµ‹è¯•ç”¨ä¾‹1ï¼šç¼ºå°‘æ ¸å¿ƒåˆ—")
        invalid_price_data = pd.DataFrame({
            'ts_code': ['600000.SH'] * 100,
            'trade_date': pd.date_range('2024-01-01', periods=100).strftime('%Y%m%d')
            # ç¼ºå°‘ close, vol åˆ—
        })
        
        features = predictor.generate_features_from_price(invalid_price_data)
        
        # åº”è¯¥è¿”å›ç©ºDataFrame
        assert features.empty, "ç¼ºå°‘æ ¸å¿ƒåˆ—æ—¶åº”è¯¥è¿”å›ç©ºDataFrame"
        print("âœ“ ç¼ºå°‘æ ¸å¿ƒåˆ—æ—¶è¿”å›ç©ºDataFrame")
        
        # æµ‹è¯•ç”¨ä¾‹2ï¼šæœ‰æ•ˆæ•°æ®
        print("\næµ‹è¯•ç”¨ä¾‹2ï¼šæœ‰æ•ˆæ•°æ®")
        np.random.seed(42)
        valid_price_data = pd.DataFrame({
            'ts_code': ['600000.SH'] * 100,
            'trade_date': pd.date_range('2024-01-01', periods=100).strftime('%Y%m%d'),
            'open': np.random.uniform(9, 11, 100),
            'high': np.random.uniform(9, 11, 100),
            'low': np.random.uniform(9, 11, 100),
            'close': np.random.uniform(9, 11, 100),
            'vol': np.random.uniform(1000000, 10000000, 100),
            'amount': np.random.uniform(10000000, 100000000, 100)
        })
        
        # ç¡®ä¿ä»·æ ¼æ•°æ®åˆç†
        valid_price_data['high'] = valid_price_data[['open', 'close']].max(axis=1) + np.random.uniform(0, 0.5, 100)
        valid_price_data['low'] = valid_price_data[['open', 'close']].min(axis=1) - np.random.uniform(0, 0.5, 100)
        
        features = predictor.generate_features_from_price(valid_price_data)
        
        # éªŒè¯ç‰¹å¾æ˜¯å¦ç”Ÿæˆ
        assert not features.empty, "æœ‰æ•ˆæ•°æ®åº”è¯¥ç”Ÿæˆç‰¹å¾"
        assert 'ts_code' in features.columns, "ç‰¹å¾åº”è¯¥åŒ…å«è‚¡ç¥¨ä»£ç "
        assert 'trade_date' in features.columns, "ç‰¹å¾åº”è¯¥åŒ…å«äº¤æ˜“æ—¥æœŸ"
        print(f"âœ“ æœ‰æ•ˆæ•°æ®ç”Ÿæˆç‰¹å¾æˆåŠŸï¼Œå…±{len(features)}è¡Œ")
        
        print("\nâœ“ ç‰¹å¾ç”Ÿæˆï¼ˆå¸¦æ•°æ®æ ¡éªŒï¼‰æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"ç‰¹å¾ç”Ÿæˆï¼ˆå¸¦æ•°æ®æ ¡éªŒï¼‰æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    """
    print("\n" + "="*80)
    print("predictor.py ä»£ç å¥å£®æ€§ä¼˜åŒ–æµ‹è¯•")
    print("="*80)
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results.append(("å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†", test_anomaly_detection()))
    results.append(("æ•°æ®æ ¡éªŒ", test_data_validation()))
    results.append(("ç¼ºå¤±å€¼å¡«å……ç­–ç•¥", test_missing_value_filling()))
    results.append(("æ¨¡å‹åŠ è½½ä¸å®¹é”™", test_model_loading_and_fallback()))
    results.append(("è·¯å¾„ä¸ç¯å¢ƒé€‚é…", test_path_and_environment_adaptation()))
    results.append(("ç‰¹å¾ç”Ÿæˆï¼ˆå¸¦æ•°æ®æ ¡éªŒï¼‰", test_generate_features_with_validation()))
    
    # æ‰“å°æµ‹è¯•ç»“æœæ±‡æ€»
    print("\n" + "="*80)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*80)
    
    total_tests = len(results)
    passed_tests = sum(1 for _, result in results if result)
    failed_tests = total_tests - passed_tests
    
    for test_name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
    
    print(f"\næ€»è®¡: {total_tests} ä¸ªæµ‹è¯•")
    print(f"é€šè¿‡: {passed_tests} ä¸ª")
    print(f"å¤±è´¥: {failed_tests} ä¸ª")
    
    if failed_tests == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)
